{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "envuQ0rsaYwV"
      },
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llWh2k3AO5xi",
        "outputId": "5184e6d1-a50e-45cb-958d-5f846bd297a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWs5bznoaSuZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRg77GNTW7oo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set the seed value (e.g., 42)\n",
        "seed_value = 64\n",
        "\n",
        "# Seed the random number generators\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed(seed_value)  # If using CUDA\n",
        "torch.cuda.manual_seed_all(seed_value)  # If using multiple GPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdQUCFTIj7vz"
      },
      "source": [
        "# 1. Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-rkVUyf97Ot"
      },
      "outputs": [],
      "source": [
        "# # Example label mappings\n",
        "pos_label2id = {\n",
        "    'CC' : 0,  # Coordinating conjunction\n",
        "    'CD' : 1,  # Cardinal number\n",
        "    'OD' : 2,  # Ordinal Number\n",
        "    'DT' : 3,  # Determiner\n",
        "    'FW' : 4,  # Foreign word\n",
        "    'IN' : 5,  # Preposition\n",
        "    'JJ' : 6, # Adjective\n",
        "    'MD' : 7, # Modal\n",
        "    'NEG' : 8, # Negation\n",
        "    'NN' : 9, # Noun\n",
        "    'NNP' : 10, # Proper Noun\n",
        "    'NND' : 11, # Classifier\n",
        "    'PR' : 12, # Demonstrative Pronoun\n",
        "    'PRP' : 13, # Personal Pronoun\n",
        "    'RB' : 14, # Adverb\n",
        "    'RP' : 15, # Particle\n",
        "    'SC' : 16, # Subordinating Conjunction\n",
        "    'SYM' : 17, # Symbol\n",
        "    'UH' : 18, # Interjection\n",
        "    'VB' : 19, # Verb\n",
        "    'WH': 20, # Question\n",
        "    'Z' : 21 # Punctuation\n",
        "}\n",
        "\n",
        "ner_label2id = {\n",
        "    'O': 0,      # Outside (non-entity)\n",
        "    'B-LOC': 1,  # Beginning of a location entity\n",
        "    'I-LOC': 2,  # Inside a location entity\n",
        "    'B-PERSON': 3,  # Beginning of a person entity\n",
        "    'I-PERSON': 4,  # Inside a person entity\n",
        "    'B-ORG': 5,  # Beginning of an organization entity\n",
        "    'I-ORG': 6,  # Inside an organization entity\n",
        "    'B-EVENT': 7, # Beginning of a miscellaneous entity\n",
        "    'I-EVENT': 8,  # Inside a miscellaneous\n",
        "    'B-GPE': 9,  # Beginning of a geopolitical entity\n",
        "    'I-GPE': 10  # Inside a geopolitical entity\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf-N_hox27vc"
      },
      "outputs": [],
      "source": [
        "# # # Example label mappings\n",
        "# pos_label2id = {\n",
        "#     'CC' : 0,  # Coordinating conjunction\n",
        "#     'CD' : 1,  # Cardinal number\n",
        "#     'OD' : 2,  # Ordinal Number\n",
        "#     'DT' : 3,  # Determiner\n",
        "#     'FW' : 4,  # Foreign word\n",
        "#     'IN' : 5,  # Preposition\n",
        "#     'JJ' : 6, # Adjective\n",
        "#     'MD' : 7, # Modal\n",
        "#     'NEG' : 8, # Negation\n",
        "#     'NN' : 9, # Noun\n",
        "#     'NNP' : 10, # Proper Noun\n",
        "#     'NND' : 11, # Classifier\n",
        "#     'PR' : 12, # Demonstrative Pronoun\n",
        "#     'PRP' : 13, # Personal Pronoun\n",
        "#     'RB' : 14, # Adverb\n",
        "#     'RP' : 15, # Particle\n",
        "#     'SC' : 16, # Subordinating Conjunction\n",
        "#     'SYM' : 17, # Symbol\n",
        "#     'UH' : 18, # Interjection\n",
        "#     'VB' : 19, # Verb\n",
        "#     'WH': 20, # Question\n",
        "#     'X' : 21, # Unknown\n",
        "#     'Z' : 22 # Punctuation\n",
        "# }\n",
        "\n",
        "# ner_label2id = {\n",
        "#     'O': 0,      # Outside (non-entity)\n",
        "#     'B-LOC': 1,  # Beginning of a location entity\n",
        "#     'I-LOC': 2,  # Inside a location entity\n",
        "#     'B-PERSON': 3,  # Beginning of a person entity\n",
        "#     'I-PERSON': 4,  # Inside a person entity\n",
        "#     'B-ORG': 5,  # Beginning of an organization entity\n",
        "#     'I-ORG': 6,  # Inside an organization entity\n",
        "#     'B-EVENT': 7, # Beginning of a miscellaneous entity\n",
        "#     'I-EVENT': 8,  # Inside a miscellaneous\n",
        "#     'B-MISC': 9,  # Beginning of a miscellaneous entity\n",
        "#     'I-MISC': 10,  # Inside a miscellaneous\n",
        "#     'B-GPE': 11,  # Beginning of a geopolitical entity\n",
        "#     'I-GPE': 12  # Inside a geopolitical entity\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_QeZBGaj1XM"
      },
      "outputs": [],
      "source": [
        "pos_id2label = {v: k for k, v in pos_label2id.items()}\n",
        "ner_id2label = {v: k for k, v in ner_label2id.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZas9aZSYyEb"
      },
      "source": [
        "# 2. Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1P5-wXWT5FB"
      },
      "outputs": [],
      "source": [
        "full_dataset = pd.read_csv('/content/FinalDataset - Fix - Rechecked LOC n GPE - NoMISC - Sheet1.csv')\n",
        "\n",
        "full_dataset = full_dataset[:1026]\n",
        "\n",
        "import ast\n",
        "\n",
        "for col in full_dataset.columns:\n",
        "    full_dataset[col] = full_dataset[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdTZ69ukmhUS"
      },
      "outputs": [],
      "source": [
        "for index, row in full_dataset.iterrows():\n",
        "  if len(row['tokens']) != len(row['pos_labels']) or len(row['tokens']) != len(row['ner_labels']):\n",
        "    print(index, len(row['tokens']), len(row['ner_labels']), len(row['pos_labels']), sep='\\t')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doZstrildPte",
        "outputId": "f3e6c425-101f-4a9b-88ad-bf4142b0699a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "all_ner_tags = [tag for sent in full_dataset['ner_labels'] for tag in sent]\n",
        "ner_counts = Counter(all_ner_tags)\n",
        "\n",
        "labels, counts = zip(*sorted(ner_counts.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(labels, counts)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"NER Tag Distribution\")\n",
        "plt.xlabel(\"NER Tag\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "all_pos_tags = [tag[0] if isinstance(tag, list) else tag for sent in full_dataset['pos_labels'] for tag in sent]\n",
        "pos_counts = Counter(all_pos_tags)\n",
        "\n",
        "labels_pos, counts_pos = zip(*sorted(pos_counts.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(labels_pos, counts_pos)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"POS Tag Distribution\")\n",
        "plt.xlabel(\"POS Tag\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9ROcaW-zxep"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, val_set = train_test_split(full_dataset, test_size=0.1, random_state=seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x3uU_DKz7Rf",
        "outputId": "d0cc646a-c4a9-4796-9be2-72812af2f60f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "923\n",
            "103\n"
          ]
        }
      ],
      "source": [
        "print(len(train_set))\n",
        "print(len(val_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFCeX0O9z9Pa",
        "outputId": "3b5d6f48-a396-4d4e-e352-a7adb4a92ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokens        [cara, ke, blok, m, pake, transum, dari, bunda...\n",
            "ner_labels    [O, O, B-LOC, I-LOC, O, O, O, B-LOC, I-LOC, O,...\n",
            "pos_labels    [NN, IN, NNP, NNP, VB, NN, IN, NNP, NNP, OD, Z...\n",
            "Name: 1016, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(train_set.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kovedTwHU0bO"
      },
      "source": [
        "# 4. Non CRF Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcF6JKHfV6xb"
      },
      "source": [
        "## 4.0. Tokenizer and Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "tqvA0kq2V6xb",
        "outputId": "f7f620f6-f9eb-44aa-a87b-c9a7dee45218"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb1e8a541c7d442082d12b23bacc3068",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "476e4689f3ac417a8df66598157da193",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "211ad00f69224c178f93d23512ccc40e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aada8f76b7ab417c8da476c603b9f270",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import XLMRobertaTokenizerFast\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A6ypWq-YSZD"
      },
      "outputs": [],
      "source": [
        "def align_labels(encoding, pos_labels, ner_labels, pos_label2id, ner_label2id):\n",
        "    all_pos, all_ner = [], []\n",
        "    for idx, word_ids in enumerate(encoding.word_ids(batch_index=i) for i in range(len(encoding['input_ids']))):\n",
        "        pos_seq, ner_seq = [], []\n",
        "        words_pos = pos_labels[idx] if idx < len(pos_labels) else []\n",
        "        words_ner = ner_labels[idx] if idx < len(ner_labels) else []\n",
        "        w_idx = 0\n",
        "\n",
        "        for token_idx, word_id in enumerate(word_ids):\n",
        "            if word_id is None:\n",
        "                pos_seq.append(-100)\n",
        "                ner_seq.append(-100)\n",
        "\n",
        "            elif word_id != word_ids[token_idx-1] if token_idx>0 else True:\n",
        "                # first subword\n",
        "                if w_idx < len(words_pos):\n",
        "                  try:\n",
        "                      pos_tag = words_pos[w_idx]\n",
        "                      if isinstance(pos_tag, list):\n",
        "                          pos_tag = pos_tag[0] if pos_tag else None\n",
        "\n",
        "                      # akses langsung—KeyError jika pos_tag tidak ada di pos_label2id\n",
        "                      pos_seq.append(pos_label2id[pos_tag])\n",
        "\n",
        "                      if w_idx < len(words_ner):\n",
        "                          ner_tag = words_ner[w_idx]\n",
        "                          if isinstance(ner_tag, list):\n",
        "                              ner_tag = ner_tag[0] if ner_tag else None\n",
        "\n",
        "                          # akses langsung—KeyError jika ner_tag tidak ada di ner_label2id\n",
        "                          ner_seq.append(ner_label2id[ner_tag])\n",
        "                      else:\n",
        "                          ner_seq.append(-100)\n",
        "\n",
        "                      w_idx += 1\n",
        "                  except KeyError:\n",
        "                    print(f\"Index {idx}\")\n",
        "                    raise\n",
        "\n",
        "                else:\n",
        "                    pos_seq.append(-100)\n",
        "                    ner_seq.append(-100)\n",
        "\n",
        "            else:\n",
        "                pos_seq.append(-100)\n",
        "                # ulangi label NER sebelumnya untuk subword\n",
        "                ner_seq.append(ner_seq[-1])\n",
        "\n",
        "        all_pos.append(pos_seq)\n",
        "        all_ner.append(ner_seq)\n",
        "\n",
        "    return all_pos, all_ner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQF6t75SV6xc"
      },
      "outputs": [],
      "source": [
        "encoded_train = tokenizer(\n",
        "    train_set['tokens'].tolist(),\n",
        "    is_split_into_words=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "encoded_val = tokenizer(\n",
        "    val_set['tokens'].tolist(),\n",
        "    is_split_into_words=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "aligned_pos_labels_train, aligned_ner_labels_train = align_labels(\n",
        "    encoded_train,\n",
        "    train_set['pos_labels'].tolist(),\n",
        "    train_set['ner_labels'].tolist(),\n",
        "    pos_label2id,\n",
        "    ner_label2id\n",
        ")\n",
        "\n",
        "aligned_pos_labels_val, aligned_ner_labels_val = align_labels(\n",
        "    encoded_val,\n",
        "    val_set['pos_labels'].tolist(),\n",
        "    val_set['ner_labels'].tolist(),\n",
        "    pos_label2id,\n",
        "    ner_label2id\n",
        ")\n",
        "\n",
        "# Get the device from encoded['input_ids']\n",
        "device = encoded_train['input_ids'].device\n",
        "\n",
        "encoded_pos_labels_train = torch.tensor(aligned_pos_labels_train).to(device)\n",
        "encoded_ner_labels_train = torch.tensor(aligned_ner_labels_train).to(device)\n",
        "\n",
        "encoded_pos_labels_val = torch.tensor(aligned_pos_labels_val).to(device)\n",
        "encoded_ner_labels_val = torch.tensor(aligned_ner_labels_val).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvQbvQodV6xd",
        "outputId": "210d7a83-4931-4ee8-f165-58b16055206e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s>',\n",
              " '▁cara',\n",
              " '▁ke',\n",
              " '▁blok',\n",
              " '▁m',\n",
              " '▁pake',\n",
              " '▁trans',\n",
              " 'um',\n",
              " '▁dari',\n",
              " '▁bunda',\n",
              " 'ran',\n",
              " '▁hi',\n",
              " '▁1',\n",
              " '▁',\n",
              " '.',\n",
              " '▁naik',\n",
              " '▁mrt',\n",
              " '▁dari',\n",
              " '▁bund',\n",
              " '▁hi',\n",
              " '▁turun',\n",
              " '▁duk',\n",
              " 'uh',\n",
              " '▁atas',\n",
              " '▁2',\n",
              " '▁',\n",
              " '.',\n",
              " '▁dari',\n",
              " '▁duk',\n",
              " 'uh',\n",
              " '▁atas',\n",
              " '▁jalan',\n",
              " '▁ke',\n",
              " '▁st',\n",
              " '▁b',\n",
              " 'ni',\n",
              " '▁city',\n",
              " '▁terus',\n",
              " '▁naik',\n",
              " '▁kr',\n",
              " 'l',\n",
              " '▁bas',\n",
              " 'o',\n",
              " 'etta',\n",
              " '▁turun',\n",
              " '▁ra',\n",
              " 'wa',\n",
              " '▁bu',\n",
              " 'aya',\n",
              " '▁3',\n",
              " '▁',\n",
              " '.',\n",
              " '▁dari',\n",
              " '▁ra',\n",
              " 'wa',\n",
              " '▁bu',\n",
              " 'aya',\n",
              " '▁naik',\n",
              " '▁kr',\n",
              " 'l',\n",
              " '▁arah',\n",
              " '▁du',\n",
              " 'ri',\n",
              " '▁turun',\n",
              " '▁gro',\n",
              " 'gol',\n",
              " '▁4',\n",
              " '▁',\n",
              " '.',\n",
              " '▁dari',\n",
              " '▁gro',\n",
              " 'gol',\n",
              " '▁naik',\n",
              " '▁trans',\n",
              " 'ja',\n",
              " 'karta',\n",
              " '▁arah',\n",
              " '▁pin',\n",
              " 'ang',\n",
              " '▁ran',\n",
              " 'ti',\n",
              " '▁turun',\n",
              " '▁pan',\n",
              " 'cor',\n",
              " 'an',\n",
              " '</s>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(encoded_train['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-o7oR6V6xd",
        "outputId": "52f9f900-b1ba-4295-9490-74f55ea3528f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-100,    0,    0,    0,    0,    0,    0,    0, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_ner_labels_train[103]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdCQx1mOV6xd",
        "outputId": "5c54ded7-ab27-44a6-e86a-1e561ebbed1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-100,    9,    5,   10,   10,   19,    9, -100,    5,   10, -100,   10,\n",
              "           2,   21, -100,   19,    9,    5,   10,   10,   19,   10, -100,   10,\n",
              "           2,   21, -100,    5,   10, -100,   10,   19,    5,   10,   10, -100,\n",
              "          10,   14,   19,    9, -100,   10, -100, -100,   19,   10, -100,   10,\n",
              "        -100,    2,   21, -100,    5,   10, -100,   10, -100,   19,    9, -100,\n",
              "           9,   10, -100,   19,   10, -100,    2,   21, -100,    5,   10, -100,\n",
              "           5,   10, -100, -100,    9,   10, -100,   10, -100,   19,   10, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_pos_labels_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abD_yaWFj-CC"
      },
      "source": [
        "## 4.1 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGJmm2W-tBO6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaModel, XLMRobertaPreTrainedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bArDq6laP0Sw"
      },
      "outputs": [],
      "source": [
        "class XLMRobertaForMultiTaskTokenClassification(XLMRobertaPreTrainedModel):\n",
        "    def __init__(self, config, num_pos_labels, num_ner_labels):\n",
        "        super().__init__(config)\n",
        "        self.num_pos_labels = num_pos_labels\n",
        "        self.num_ner_labels = num_ner_labels\n",
        "\n",
        "        self.roberta = XLMRobertaModel(config)  # Base model\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        # Two classification heads: One for POS, One for NER\n",
        "        self.classifier_pos = nn.Linear(config.hidden_size, num_pos_labels)\n",
        "        self.classifier_ner = nn.Linear(config.hidden_size, num_ner_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels_pos=None, labels_ner=None):\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        logits_pos = self.classifier_pos(sequence_output)\n",
        "        logits_ner = self.classifier_ner(sequence_output)\n",
        "\n",
        "        loss = 0\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "        if labels_pos is not None:\n",
        "            pos_loss = loss_fct(logits_pos.view(-1, self.num_pos_labels), labels_pos.view(-1))\n",
        "            loss += pos_loss\n",
        "            # print(pos_loss)\n",
        "\n",
        "\n",
        "        if labels_ner is not None:\n",
        "            ner_loss = loss_fct(logits_ner.view(-1, self.num_ner_labels), labels_ner.view(-1))\n",
        "            loss += ner_loss\n",
        "            # print(ner_loss)\n",
        "\n",
        "\n",
        "        return {\"loss\": loss, \"logits_pos\": logits_pos, \"logits_ner\": logits_ner}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Yd91RuG8zMNO",
        "outputId": "1c8dbdd5-d271-4b1d-c291-5c71759788e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78f2fd6709e445479765d1262af8db54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import XLMRobertaConfig\n",
        "from transformers import XLMRobertaModel\n",
        "\n",
        "config = XLMRobertaConfig.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Specify the number of POS and NER labels\n",
        "num_pos_labels = len(pos_label2id)  # Example: Adjust based on your POS label set\n",
        "num_ner_labels = len(ner_label2id)   # Example: Adjust based on your NER label set\n",
        "\n",
        "# Instantiate the model\n",
        "model = XLMRobertaForMultiTaskTokenClassification(config, num_pos_labels, num_ner_labels)\n",
        "model.roberta = XLMRobertaModel.from_pretrained('xlm-roberta-base', config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrljE4S6duPE"
      },
      "source": [
        "## 4.2 Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc1BNoi6iI91",
        "outputId": "d7451adf-0c2d-4fac-f6d5-67f76cca6cfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "Train Loss: 4.3704\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.00      0.00      0.00        20\n",
            "          CD       0.00      0.00      0.00        38\n",
            "          DT       0.00      0.00      0.00        15\n",
            "          FW       0.00      0.00      0.00         4\n",
            "          IN       0.00      0.00      0.00        88\n",
            "          JJ       0.00      0.00      0.00       122\n",
            "          MD       0.00      0.00      0.00        30\n",
            "         NEG       0.00      0.00      0.00        25\n",
            "          NN       0.21      0.98      0.35       327\n",
            "         NND       0.00      0.00      0.00         8\n",
            "         NNP       0.67      0.01      0.02       222\n",
            "          OD       0.00      0.00      0.00         6\n",
            "          PR       0.00      0.00      0.00        25\n",
            "         PRP       0.00      0.00      0.00        53\n",
            "          RB       0.00      0.00      0.00        95\n",
            "          RP       0.00      0.00      0.00        15\n",
            "          SC       0.00      0.00      0.00        41\n",
            "         SYM       0.00      0.00      0.00        39\n",
            "          UH       0.00      0.00      0.00        46\n",
            "          VB       0.38      0.06      0.11       206\n",
            "          WH       0.00      0.00      0.00        13\n",
            "           Z       0.00      0.00      0.00       132\n",
            "\n",
            "    accuracy                           0.21      1570\n",
            "   macro avg       0.06      0.05      0.02      1570\n",
            "weighted avg       0.19      0.21      0.09      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.00      0.00      0.00         6\n",
            "       B-GPE       0.00      0.00      0.00        48\n",
            "       B-LOC       0.00      0.00      0.00        34\n",
            "       B-ORG       0.00      0.00      0.00        65\n",
            "    B-PERSON       0.00      0.00      0.00       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.00      0.00      0.00        15\n",
            "       I-LOC       0.00      0.00      0.00        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.00      0.00      0.00        12\n",
            "           O       0.81      1.00      0.89      1807\n",
            "\n",
            "    accuracy                           0.81      2241\n",
            "   macro avg       0.07      0.09      0.08      2241\n",
            "weighted avg       0.65      0.81      0.72      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/40\n",
            "Train Loss: 2.6603\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.05      0.10        20\n",
            "          CD       1.00      0.11      0.19        38\n",
            "          DT       0.00      0.00      0.00        15\n",
            "          FW       0.00      0.00      0.00         4\n",
            "          IN       0.71      0.80      0.75        88\n",
            "          JJ       0.71      0.46      0.56       122\n",
            "          MD       0.00      0.00      0.00        30\n",
            "         NEG       1.00      0.40      0.57        25\n",
            "          NN       0.70      0.75      0.72       327\n",
            "         NND       0.00      0.00      0.00         8\n",
            "         NNP       0.65      0.91      0.76       222\n",
            "          OD       0.00      0.00      0.00         6\n",
            "          PR       1.00      0.76      0.86        25\n",
            "         PRP       0.94      0.92      0.93        53\n",
            "          RB       0.49      0.76      0.59        95\n",
            "          RP       0.00      0.00      0.00        15\n",
            "          SC       0.86      0.78      0.82        41\n",
            "         SYM       0.00      0.00      0.00        39\n",
            "          UH       0.78      0.15      0.25        46\n",
            "          VB       0.65      0.85      0.74       206\n",
            "          WH       0.00      0.00      0.00        13\n",
            "           Z       0.72      1.00      0.84       132\n",
            "\n",
            "    accuracy                           0.68      1570\n",
            "   macro avg       0.51      0.40      0.39      1570\n",
            "weighted avg       0.65      0.68      0.64      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.00      0.00      0.00         6\n",
            "       B-GPE       0.00      0.00      0.00        48\n",
            "       B-LOC       0.00      0.00      0.00        34\n",
            "       B-ORG       0.00      0.00      0.00        65\n",
            "    B-PERSON       0.57      0.85      0.68       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.00      0.00      0.00        15\n",
            "       I-LOC       0.28      0.75      0.40        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.00      0.00      0.00        12\n",
            "           O       0.96      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.87      2241\n",
            "   macro avg       0.16      0.23      0.19      2241\n",
            "weighted avg       0.83      0.87      0.84      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/40\n",
            "Train Loss: 1.3033\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.86      0.90      0.88        20\n",
            "          CD       0.81      1.00      0.89        38\n",
            "          DT       0.00      0.00      0.00        15\n",
            "          FW       0.00      0.00      0.00         4\n",
            "          IN       0.82      0.91      0.86        88\n",
            "          JJ       0.78      0.77      0.77       122\n",
            "          MD       0.96      0.80      0.87        30\n",
            "         NEG       0.78      1.00      0.88        25\n",
            "          NN       0.85      0.76      0.80       327\n",
            "         NND       0.00      0.00      0.00         8\n",
            "         NNP       0.74      0.92      0.82       222\n",
            "          OD       0.00      0.00      0.00         6\n",
            "          PR       0.95      0.84      0.89        25\n",
            "         PRP       0.94      0.96      0.95        53\n",
            "          RB       0.71      0.87      0.78        95\n",
            "          RP       1.00      0.27      0.42        15\n",
            "          SC       0.81      0.95      0.88        41\n",
            "         SYM       0.96      0.62      0.75        39\n",
            "          UH       0.72      0.72      0.72        46\n",
            "          VB       0.90      0.81      0.85       206\n",
            "          WH       0.80      0.92      0.86        13\n",
            "           Z       0.92      1.00      0.96       132\n",
            "\n",
            "    accuracy                           0.83      1570\n",
            "   macro avg       0.70      0.68      0.67      1570\n",
            "weighted avg       0.82      0.83      0.81      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.00      0.00      0.00         6\n",
            "       B-GPE       1.00      0.04      0.08        48\n",
            "       B-LOC       0.00      0.00      0.00        34\n",
            "       B-ORG       0.31      0.23      0.26        65\n",
            "    B-PERSON       0.68      0.70      0.69       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.00      0.00      0.00        15\n",
            "       I-LOC       0.26      0.96      0.41        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.00      0.00      0.00        12\n",
            "           O       0.97      0.96      0.97      1807\n",
            "\n",
            "    accuracy                           0.87      2241\n",
            "   macro avg       0.29      0.26      0.22      2241\n",
            "weighted avg       0.88      0.87      0.86      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/40\n",
            "Train Loss: 0.7615\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.95      0.97        20\n",
            "          CD       0.76      1.00      0.86        38\n",
            "          DT       0.85      0.73      0.79        15\n",
            "          FW       0.00      0.00      0.00         4\n",
            "          IN       0.94      0.95      0.95        88\n",
            "          JJ       0.84      0.80      0.82       122\n",
            "          MD       1.00      0.73      0.85        30\n",
            "         NEG       0.86      1.00      0.93        25\n",
            "          NN       0.85      0.80      0.82       327\n",
            "         NND       1.00      0.12      0.22         8\n",
            "         NNP       0.78      0.88      0.82       222\n",
            "          OD       0.00      0.00      0.00         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.96      0.94      0.95        53\n",
            "          RB       0.84      0.91      0.87        95\n",
            "          RP       1.00      0.67      0.80        15\n",
            "          SC       0.93      0.95      0.94        41\n",
            "         SYM       0.92      0.92      0.92        39\n",
            "          UH       0.69      0.78      0.73        46\n",
            "          VB       0.88      0.87      0.88       206\n",
            "          WH       0.76      1.00      0.87        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.86      1570\n",
            "   macro avg       0.81      0.77      0.77      1570\n",
            "weighted avg       0.86      0.86      0.86      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.00      0.00      0.00         6\n",
            "       B-GPE       0.61      0.65      0.63        48\n",
            "       B-LOC       0.52      0.74      0.61        34\n",
            "       B-ORG       0.35      0.43      0.39        65\n",
            "    B-PERSON       0.84      0.62      0.71       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.00      0.00      0.00        15\n",
            "       I-LOC       0.53      0.75      0.62        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.00      0.00      0.00        12\n",
            "           O       0.95      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.89      2241\n",
            "   macro avg       0.35      0.38      0.36      2241\n",
            "weighted avg       0.88      0.89      0.89      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/40\n",
            "Train Loss: 0.5460\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.83      1.00      0.90        38\n",
            "          DT       0.75      0.80      0.77        15\n",
            "          FW       0.00      0.00      0.00         4\n",
            "          IN       0.97      0.94      0.95        88\n",
            "          JJ       0.83      0.79      0.81       122\n",
            "          MD       0.93      0.83      0.88        30\n",
            "         NEG       0.89      1.00      0.94        25\n",
            "          NN       0.85      0.85      0.85       327\n",
            "         NND       0.67      0.25      0.36         8\n",
            "         NNP       0.83      0.89      0.86       222\n",
            "          OD       0.00      0.00      0.00         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.94      0.94      0.94        53\n",
            "          RB       0.79      0.92      0.85        95\n",
            "          RP       1.00      0.73      0.85        15\n",
            "          SC       0.93      0.95      0.94        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.81      0.76      0.79        46\n",
            "          VB       0.90      0.84      0.87       206\n",
            "          WH       0.76      1.00      0.87        13\n",
            "           Z       0.99      1.00      1.00       132\n",
            "\n",
            "    accuracy                           0.87      1570\n",
            "   macro avg       0.80      0.78      0.78      1570\n",
            "weighted avg       0.87      0.87      0.87      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.00      0.00      0.00         6\n",
            "       B-GPE       0.42      0.92      0.58        48\n",
            "       B-LOC       0.65      0.59      0.62        34\n",
            "       B-ORG       0.65      0.34      0.44        65\n",
            "    B-PERSON       0.76      0.90      0.83       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.00      0.00      0.00        15\n",
            "       I-LOC       0.67      0.64      0.65        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       1.00      0.25      0.40        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.91      2241\n",
            "   macro avg       0.47      0.42      0.41      2241\n",
            "weighted avg       0.91      0.91      0.91      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/40\n",
            "Train Loss: 0.4452\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      1.00      1.00        20\n",
            "          CD       0.83      1.00      0.90        38\n",
            "          DT       0.76      0.87      0.81        15\n",
            "          FW       0.00      0.00      0.00         4\n",
            "          IN       0.93      0.94      0.94        88\n",
            "          JJ       0.87      0.80      0.83       122\n",
            "          MD       0.96      0.87      0.91        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.81      0.85       327\n",
            "         NND       0.67      0.25      0.36         8\n",
            "         NNP       0.81      0.91      0.86       222\n",
            "          OD       0.00      0.00      0.00         6\n",
            "          PR       0.95      0.84      0.89        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.83      0.91      0.87        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.92      0.90      0.91        39\n",
            "          UH       0.68      0.87      0.76        46\n",
            "          VB       0.88      0.91      0.90       206\n",
            "          WH       0.92      0.92      0.92        13\n",
            "           Z       0.98      0.98      0.98       132\n",
            "\n",
            "    accuracy                           0.88      1570\n",
            "   macro avg       0.81      0.80      0.79      1570\n",
            "weighted avg       0.88      0.88      0.88      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.00      0.00      0.00         6\n",
            "       B-GPE       0.53      0.88      0.66        48\n",
            "       B-LOC       0.83      0.71      0.76        34\n",
            "       B-ORG       0.59      0.15      0.24        65\n",
            "    B-PERSON       0.69      0.86      0.77       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.00      0.00      0.00        15\n",
            "       I-LOC       0.73      0.75      0.74        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       1.00      0.50      0.67        12\n",
            "           O       0.96      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.91      2241\n",
            "   macro avg       0.48      0.44      0.44      2241\n",
            "weighted avg       0.90      0.91      0.90      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/40\n",
            "Train Loss: 0.3256\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.90      1.00      0.95        38\n",
            "          DT       0.68      0.87      0.76        15\n",
            "          FW       0.00      0.00      0.00         4\n",
            "          IN       0.95      0.95      0.95        88\n",
            "          JJ       0.80      0.83      0.81       122\n",
            "          MD       0.84      0.90      0.87        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.81      0.85       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.82      0.87      0.84       222\n",
            "          OD       1.00      0.50      0.67         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.96      0.94      0.95        53\n",
            "          RB       0.82      0.94      0.88        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.95      0.94        41\n",
            "         SYM       0.97      0.85      0.90        39\n",
            "          UH       0.78      0.87      0.82        46\n",
            "          VB       0.87      0.88      0.87       206\n",
            "          WH       0.81      1.00      0.90        13\n",
            "           Z       0.98      1.00      0.99       132\n",
            "\n",
            "    accuracy                           0.88      1570\n",
            "   macro avg       0.85      0.82      0.83      1570\n",
            "weighted avg       0.88      0.88      0.88      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.60      0.50      0.55         6\n",
            "       B-GPE       0.67      0.46      0.54        48\n",
            "       B-LOC       0.64      0.79      0.71        34\n",
            "       B-ORG       0.68      0.40      0.50        65\n",
            "    B-PERSON       0.81      0.84      0.82       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.46      0.40      0.43        15\n",
            "       I-LOC       0.59      0.80      0.68        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.86      0.50      0.63        12\n",
            "           O       0.96      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.92      2241\n",
            "   macro avg       0.57      0.51      0.53      2241\n",
            "weighted avg       0.91      0.92      0.91      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/40\n",
            "Train Loss: 0.2308\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.93      1.00      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.93      0.97      0.95        88\n",
            "          JJ       0.85      0.77      0.81       122\n",
            "          MD       0.93      0.90      0.92        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.85      0.86      0.86       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.87      0.86      0.86       222\n",
            "          OD       1.00      0.67      0.80         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.96      0.94      0.95        53\n",
            "          RB       0.82      0.92      0.87        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.86      0.97      0.92        39\n",
            "          UH       0.80      0.85      0.82        46\n",
            "          VB       0.88      0.89      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       1.00      0.97      0.98       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.85      0.87      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.67      0.67      0.67         6\n",
            "       B-GPE       0.78      0.75      0.77        48\n",
            "       B-LOC       0.78      0.74      0.76        34\n",
            "       B-ORG       0.78      0.43      0.55        65\n",
            "    B-PERSON       0.92      0.75      0.83       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.50      0.60      0.55        15\n",
            "       I-LOC       0.73      0.80      0.77        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.73      0.67      0.70        12\n",
            "           O       0.95      0.99      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.62      0.58      0.60      2241\n",
            "weighted avg       0.92      0.93      0.92      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/40\n",
            "Train Loss: 0.2006\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      1.00      1.00        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.95      0.93      0.94        88\n",
            "          JJ       0.79      0.85      0.82       122\n",
            "          MD       0.96      0.87      0.91        30\n",
            "         NEG       0.89      1.00      0.94        25\n",
            "          NN       0.87      0.85      0.86       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.83      0.87      0.85       222\n",
            "          OD       0.83      0.83      0.83         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.85      0.93      0.89        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.93      0.95      0.94        39\n",
            "          UH       0.84      0.80      0.82        46\n",
            "          VB       0.91      0.87      0.89       206\n",
            "          WH       0.92      0.92      0.92        13\n",
            "           Z       1.00      0.98      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.60      1.00      0.75         6\n",
            "       B-GPE       0.72      0.65      0.68        48\n",
            "       B-LOC       0.61      0.79      0.69        34\n",
            "       B-ORG       0.81      0.46      0.59        65\n",
            "    B-PERSON       0.87      0.79      0.83       183\n",
            "     I-EVENT       0.00      0.00      0.00         3\n",
            "       I-GPE       0.53      0.67      0.59        15\n",
            "       I-LOC       0.70      0.84      0.76        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.89      0.67      0.76        12\n",
            "           O       0.96      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.92      2241\n",
            "   macro avg       0.61      0.62      0.60      2241\n",
            "weighted avg       0.92      0.92      0.92      2241\n",
            "\n",
            "Epoch 10/40\n",
            "Train Loss: 0.1538\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      1.00      1.00        20\n",
            "          CD       0.97      0.97      0.97        38\n",
            "          DT       0.76      0.87      0.81        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.95      0.94      0.95        88\n",
            "          JJ       0.78      0.83      0.80       122\n",
            "          MD       0.80      0.93      0.86        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.89      0.83      0.86       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.81      0.92      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       0.96      0.88      0.92        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.90      0.91      0.90        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       1.00      0.87      0.93        39\n",
            "          UH       0.85      0.85      0.85        46\n",
            "          VB       0.90      0.86      0.88       206\n",
            "          WH       0.92      0.92      0.92        13\n",
            "           Z       0.99      1.00      1.00       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.87      0.88      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.67      1.00      0.80         6\n",
            "       B-GPE       0.75      0.44      0.55        48\n",
            "       B-LOC       0.56      0.79      0.66        34\n",
            "       B-ORG       0.58      0.57      0.57        65\n",
            "    B-PERSON       0.91      0.80      0.85       183\n",
            "     I-EVENT       0.50      0.67      0.57         3\n",
            "       I-GPE       0.45      0.33      0.38        15\n",
            "       I-LOC       0.54      0.84      0.66        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.86      0.50      0.63        12\n",
            "           O       0.97      0.98      0.98      1807\n",
            "\n",
            "    accuracy                           0.92      2241\n",
            "   macro avg       0.62      0.63      0.60      2241\n",
            "weighted avg       0.92      0.92      0.92      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/40\n",
            "Train Loss: 0.1164\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.90      0.97      0.94        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.98      0.95      0.97        88\n",
            "          JJ       0.80      0.80      0.80       122\n",
            "          MD       0.96      0.90      0.93        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.89      0.81      0.85       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.80      0.91      0.85       222\n",
            "          OD       0.83      0.83      0.83         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.85      0.92      0.88        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.81      0.83      0.82        46\n",
            "          VB       0.89      0.88      0.89       206\n",
            "          WH       0.87      1.00      0.93        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.86      0.87      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.75      0.69      0.72        48\n",
            "       B-LOC       0.55      0.82      0.66        34\n",
            "       B-ORG       0.47      0.55      0.51        65\n",
            "    B-PERSON       0.89      0.73      0.80       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.53      0.60      0.56        15\n",
            "       I-LOC       0.62      0.78      0.69        55\n",
            "       I-ORG       0.00      0.00      0.00        13\n",
            "    I-PERSON       0.75      0.50      0.60        12\n",
            "           O       0.97      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.92      2241\n",
            "   macro avg       0.66      0.67      0.65      2241\n",
            "weighted avg       0.92      0.92      0.92      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/40\n",
            "Train Loss: 0.1021\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      1.00      1.00        20\n",
            "          CD       0.97      0.97      0.97        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.94      0.95        88\n",
            "          JJ       0.72      0.90      0.80       122\n",
            "          MD       0.93      0.83      0.88        30\n",
            "         NEG       0.93      1.00      0.96        25\n",
            "          NN       0.89      0.83      0.86       327\n",
            "         NND       0.67      0.25      0.36         8\n",
            "         NNP       0.83      0.90      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.89      0.91      0.90        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       1.00      0.87      0.93        39\n",
            "          UH       0.88      0.80      0.84        46\n",
            "          VB       0.89      0.86      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      1.00      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.86      0.87      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.74      0.48      0.58        48\n",
            "       B-LOC       0.54      0.82      0.65        34\n",
            "       B-ORG       0.65      0.54      0.59        65\n",
            "    B-PERSON       0.93      0.81      0.87       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.45      0.33      0.38        15\n",
            "       I-LOC       0.60      0.87      0.71        55\n",
            "       I-ORG       0.40      0.31      0.35        13\n",
            "    I-PERSON       0.73      0.67      0.70        12\n",
            "           O       0.97      0.98      0.98      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.71      0.68      0.68      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/40\n",
            "Train Loss: 0.0843\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      1.00      1.00        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.94      0.95        88\n",
            "          JJ       0.84      0.80      0.82       122\n",
            "          MD       0.93      0.87      0.90        30\n",
            "         NEG       0.89      1.00      0.94        25\n",
            "          NN       0.87      0.84      0.86       327\n",
            "         NND       0.80      0.50      0.62         8\n",
            "         NNP       0.83      0.90      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       0.95      0.84      0.89        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.87      0.92      0.89        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.84      0.80      0.82        46\n",
            "          VB       0.88      0.89      0.88       206\n",
            "          WH       0.92      0.92      0.92        13\n",
            "           Z       0.99      0.98      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.87      0.88      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.72      0.60      0.66        48\n",
            "       B-LOC       0.58      0.82      0.68        34\n",
            "       B-ORG       0.72      0.58      0.64        65\n",
            "    B-PERSON       0.89      0.83      0.86       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.69      0.60      0.64        15\n",
            "       I-LOC       0.69      0.84      0.75        55\n",
            "       I-ORG       0.80      0.31      0.44        13\n",
            "    I-PERSON       0.89      0.67      0.76        12\n",
            "           O       0.97      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.79      0.72      0.73      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/40\n",
            "Train Loss: 0.0812\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.98      0.94      0.96        88\n",
            "          JJ       0.84      0.82      0.83       122\n",
            "          MD       0.96      0.87      0.91        30\n",
            "         NEG       0.89      1.00      0.94        25\n",
            "          NN       0.88      0.84      0.86       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.79      0.89      0.84       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.86      0.94      0.89        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.78      0.83      0.80        46\n",
            "          VB       0.92      0.87      0.90       206\n",
            "          WH       0.92      0.92      0.92        13\n",
            "           Z       1.00      0.99      1.00       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.87      0.88      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.78      0.75      0.77        48\n",
            "       B-LOC       0.64      0.79      0.71        34\n",
            "       B-ORG       0.64      0.57      0.60        65\n",
            "    B-PERSON       0.82      0.81      0.82       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.66      0.82      0.73        55\n",
            "       I-ORG       0.45      0.38      0.42        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.92      2241\n",
            "   macro avg       0.74      0.74      0.73      2241\n",
            "weighted avg       0.93      0.92      0.92      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/40\n",
            "Train Loss: 0.0740\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.94      0.95        88\n",
            "          JJ       0.78      0.83      0.80       122\n",
            "          MD       0.87      0.90      0.89        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.89      0.83      0.86       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.83      0.88      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.92      0.95        53\n",
            "          RB       0.85      0.93      0.88        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.92      0.90      0.91        39\n",
            "          UH       0.73      0.87      0.79        46\n",
            "          VB       0.88      0.87      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.98      0.99       132\n",
            "\n",
            "    accuracy                           0.88      1570\n",
            "   macro avg       0.90      0.86      0.87      1570\n",
            "weighted avg       0.89      0.88      0.88      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.67      1.00      0.80         6\n",
            "       B-GPE       0.79      0.65      0.71        48\n",
            "       B-LOC       0.63      0.76      0.69        34\n",
            "       B-ORG       0.59      0.57      0.58        65\n",
            "    B-PERSON       0.87      0.81      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.53      0.57        15\n",
            "       I-LOC       0.77      0.78      0.77        55\n",
            "       I-ORG       0.50      0.46      0.48        13\n",
            "    I-PERSON       0.89      0.67      0.76        12\n",
            "           O       0.97      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.75      0.72      0.73      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/40\n",
            "Train Loss: 0.0636\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.93      0.97      0.95        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.94      0.95        88\n",
            "          JJ       0.82      0.82      0.82       122\n",
            "          MD       0.89      0.83      0.86        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.86      0.85      0.85       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.81      0.87      0.84       222\n",
            "          OD       0.83      0.83      0.83         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.82      0.94      0.88        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.84      0.83      0.84        46\n",
            "          VB       0.90      0.86      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.88      1570\n",
            "   macro avg       0.90      0.85      0.87      1570\n",
            "weighted avg       0.89      0.88      0.88      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.78      0.75      0.77        48\n",
            "       B-LOC       0.64      0.82      0.72        34\n",
            "       B-ORG       0.72      0.52      0.61        65\n",
            "    B-PERSON       0.88      0.82      0.85       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.65      0.89      0.75        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.89      0.67      0.76        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.77      0.76      0.75      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/40\n",
            "Train Loss: 0.0514\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.93      0.97      0.95        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.95      0.95      0.95        88\n",
            "          JJ       0.86      0.80      0.83       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.82      0.86       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.80      0.91      0.85       222\n",
            "          OD       0.83      0.83      0.83         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.96      0.94      0.95        53\n",
            "          RB       0.84      0.92      0.88        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.78      0.85      0.81        46\n",
            "          VB       0.88      0.88      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      1.00      1.00       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.86      0.87      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.79      0.77      0.78        48\n",
            "       B-LOC       0.68      0.82      0.75        34\n",
            "       B-ORG       0.71      0.54      0.61        65\n",
            "    B-PERSON       0.82      0.86      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.65      0.87      0.74        55\n",
            "       I-ORG       0.45      0.38      0.42        13\n",
            "    I-PERSON       0.62      0.67      0.64        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.73      0.75      0.73      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/40\n",
            "Train Loss: 0.0420\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.95      0.97        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.76      0.87      0.81        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.94      0.95        88\n",
            "          JJ       0.79      0.82      0.80       122\n",
            "          MD       0.90      0.87      0.88        30\n",
            "         NEG       0.93      1.00      0.96        25\n",
            "          NN       0.88      0.86      0.87       327\n",
            "         NND       0.67      0.25      0.36         8\n",
            "         NNP       0.84      0.89      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.86      0.94      0.90        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.81      0.83      0.82        46\n",
            "          VB       0.89      0.87      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.86      0.87      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.81      0.79      0.80        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.75      0.55      0.64        65\n",
            "    B-PERSON       0.89      0.85      0.87       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.67      0.67      0.67        15\n",
            "       I-LOC       0.70      0.87      0.77        55\n",
            "       I-ORG       0.40      0.31      0.35        13\n",
            "    I-PERSON       0.89      0.67      0.76        12\n",
            "           O       0.97      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.94      2241\n",
            "   macro avg       0.77      0.74      0.75      2241\n",
            "weighted avg       0.94      0.94      0.94      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/40\n",
            "Train Loss: 0.0463\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.76      0.87      0.81        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.98      0.98      0.98        88\n",
            "          JJ       0.80      0.83      0.81       122\n",
            "          MD       0.89      0.83      0.86        30\n",
            "         NEG       0.93      1.00      0.96        25\n",
            "          NN       0.90      0.83      0.86       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.80      0.94      0.86       222\n",
            "          OD       0.83      0.83      0.83         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.96      0.94      0.95        53\n",
            "          RB       0.88      0.92      0.90        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.95      0.98      0.96        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.83      0.87      0.85        46\n",
            "          VB       0.90      0.86      0.88       206\n",
            "          WH       0.92      0.92      0.92        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.86      0.88      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.60      1.00      0.75         6\n",
            "       B-GPE       0.78      0.79      0.78        48\n",
            "       B-LOC       0.61      0.82      0.70        34\n",
            "       B-ORG       0.67      0.57      0.62        65\n",
            "    B-PERSON       0.81      0.86      0.83       183\n",
            "     I-EVENT       0.50      0.67      0.57         3\n",
            "       I-GPE       0.71      0.67      0.69        15\n",
            "       I-LOC       0.64      0.89      0.74        55\n",
            "       I-ORG       0.83      0.38      0.53        13\n",
            "    I-PERSON       0.67      0.67      0.67        12\n",
            "           O       0.98      0.96      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.71      0.75      0.71      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/40\n",
            "Train Loss: 0.0576\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       0.67      0.50      0.57         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.80      0.81      0.81       122\n",
            "          MD       0.93      0.90      0.92        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.88      0.84      0.86       327\n",
            "         NND       0.50      0.12      0.20         8\n",
            "         NNP       0.81      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.81      0.93      0.87        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       1.00      0.90      0.95        39\n",
            "          UH       0.87      0.85      0.86        46\n",
            "          VB       0.90      0.86      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      1.00      1.00       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.88      0.85      0.86      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.78      0.75      0.77        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.71      0.38      0.50        65\n",
            "    B-PERSON       0.82      0.86      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.65      0.87      0.74        55\n",
            "       I-ORG       0.50      0.54      0.52        13\n",
            "    I-PERSON       0.89      0.67      0.76        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.75      0.74      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/40\n",
            "Train Loss: 0.0413\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.97      0.97      0.97        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       0.50      0.50      0.50         4\n",
            "          IN       0.95      0.95      0.95        88\n",
            "          JJ       0.73      0.85      0.78       122\n",
            "          MD       0.86      0.83      0.85        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.91      0.82      0.86       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.83      0.90      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.96      0.97        53\n",
            "          RB       0.88      0.91      0.89        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.74      0.87      0.80        46\n",
            "          VB       0.90      0.86      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.87      0.86      0.86      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.78      0.73      0.75        48\n",
            "       B-LOC       0.78      0.82      0.80        34\n",
            "       B-ORG       0.77      0.52      0.62        65\n",
            "    B-PERSON       0.85      0.88      0.87       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.60      0.60      0.60        15\n",
            "       I-LOC       0.80      0.89      0.84        55\n",
            "       I-ORG       0.67      0.31      0.42        13\n",
            "    I-PERSON       0.89      0.67      0.76        12\n",
            "           O       0.97      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.94      2241\n",
            "   macro avg       0.81      0.73      0.75      2241\n",
            "weighted avg       0.94      0.94      0.94      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/40\n",
            "Train Loss: 0.0342\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.95      0.97        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.95      0.95      0.95        88\n",
            "          JJ       0.79      0.81      0.80       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.91      0.81      0.86       327\n",
            "         NND       0.67      0.25      0.36         8\n",
            "         NNP       0.81      0.94      0.87       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.86      0.92      0.89        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.83      0.87      0.85        46\n",
            "          VB       0.88      0.88      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.86      0.87      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.77      0.71      0.74        48\n",
            "       B-LOC       0.67      0.82      0.74        34\n",
            "       B-ORG       0.75      0.51      0.61        65\n",
            "    B-PERSON       0.81      0.88      0.85       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.56      0.60      0.58        15\n",
            "       I-LOC       0.63      0.89      0.74        55\n",
            "       I-ORG       0.46      0.46      0.46        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.74      0.74      0.73      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/40\n",
            "Train Loss: 0.0240\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.78      0.80      0.79       122\n",
            "          MD       0.87      0.90      0.89        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.92      0.82      0.87       327\n",
            "         NND       0.80      0.50      0.62         8\n",
            "         NNP       0.80      0.93      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.85      0.93      0.88        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.83      0.83      0.83        46\n",
            "          VB       0.89      0.87      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.87      0.88      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.71      0.76        48\n",
            "       B-LOC       0.67      0.82      0.74        34\n",
            "       B-ORG       0.77      0.52      0.62        65\n",
            "    B-PERSON       0.81      0.86      0.83       183\n",
            "     I-EVENT       1.00      1.00      1.00         3\n",
            "       I-GPE       0.56      0.60      0.58        15\n",
            "       I-LOC       0.60      0.89      0.72        55\n",
            "       I-ORG       0.62      0.38      0.48        13\n",
            "    I-PERSON       0.67      0.67      0.67        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.75      0.77      0.75      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/40\n",
            "Train Loss: 0.0251\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.76      0.84      0.80       122\n",
            "          MD       0.87      0.90      0.89        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.83      0.86       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.82      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       0.95      0.84      0.89        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.86      0.89      0.88        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.78      0.87      0.82        46\n",
            "          VB       0.91      0.85      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.88      0.88      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.68      0.82      0.75        34\n",
            "       B-ORG       0.82      0.49      0.62        65\n",
            "    B-PERSON       0.80      0.86      0.83       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.59      0.67      0.62        15\n",
            "       I-LOC       0.63      0.89      0.74        55\n",
            "       I-ORG       0.75      0.46      0.57        13\n",
            "    I-PERSON       0.67      0.83      0.74        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.77      0.76      0.75      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/40\n",
            "Train Loss: 0.0189\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      0.95      0.95        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.79      0.80      0.80       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.83      0.87       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.82      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.83      0.92      0.87        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.83      0.85      0.84        46\n",
            "          VB       0.90      0.88      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.84      0.79      0.82        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.75      0.46      0.57        65\n",
            "    B-PERSON       0.79      0.86      0.82       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.71      0.67      0.69        15\n",
            "       I-LOC       0.64      0.89      0.74        55\n",
            "       I-ORG       0.67      0.46      0.55        13\n",
            "    I-PERSON       0.55      0.50      0.52        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.74      0.73      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/40\n",
            "Train Loss: 0.0175\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.95      0.95      0.95        88\n",
            "          JJ       0.80      0.80      0.80       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.83      0.86       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.82      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.83      0.92      0.87        95\n",
            "          RP       0.81      0.87      0.84        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.97      0.90      0.93        39\n",
            "          UH       0.83      0.85      0.84        46\n",
            "          VB       0.90      0.86      0.88       206\n",
            "          WH       0.92      0.92      0.92        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.88      0.89      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.84      0.77      0.80        48\n",
            "       B-LOC       0.69      0.79      0.74        34\n",
            "       B-ORG       0.62      0.60      0.61        65\n",
            "    B-PERSON       0.87      0.80      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.67      0.67      0.67        15\n",
            "       I-LOC       0.70      0.80      0.75        55\n",
            "       I-ORG       0.42      0.62      0.50        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.98      0.98      0.98      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.76      0.75      2241\n",
            "weighted avg       0.94      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/40\n",
            "Train Loss: 0.0168\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.79      0.82      0.80       122\n",
            "          MD       0.84      0.90      0.87        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.83      0.87       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.83      0.91      0.87       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.83      0.93      0.88        95\n",
            "          RP       0.86      0.80      0.83        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.92      0.94        39\n",
            "          UH       0.81      0.83      0.82        46\n",
            "          VB       0.90      0.85      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.88      0.88      1570\n",
            "weighted avg       0.89      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.71      0.76        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.71      0.57      0.63        65\n",
            "    B-PERSON       0.88      0.80      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.59      0.67      0.62        15\n",
            "       I-LOC       0.69      0.89      0.78        55\n",
            "       I-ORG       0.64      0.54      0.58        13\n",
            "    I-PERSON       0.73      0.67      0.70        12\n",
            "           O       0.97      0.98      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.77      0.76      0.75      2241\n",
            "weighted avg       0.94      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/40\n",
            "Train Loss: 0.0189\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.82      0.80      0.81       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.89      0.86      0.87       327\n",
            "         NND       0.75      0.38      0.50         8\n",
            "         NNP       0.84      0.91      0.88       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.83      0.94      0.88        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.82      0.80      0.81        46\n",
            "          VB       0.89      0.87      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.87      0.88      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.80      0.81      0.80        48\n",
            "       B-LOC       0.70      0.82      0.76        34\n",
            "       B-ORG       0.65      0.55      0.60        65\n",
            "    B-PERSON       0.88      0.80      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.56      0.67      0.61        15\n",
            "       I-LOC       0.70      0.82      0.76        55\n",
            "       I-ORG       0.60      0.46      0.52        13\n",
            "    I-PERSON       0.73      0.67      0.70        12\n",
            "           O       0.97      0.98      0.98      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.75      0.75      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/40\n",
            "Train Loss: 0.0169\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.99      0.95      0.97        88\n",
            "          JJ       0.84      0.80      0.82       122\n",
            "          MD       0.87      0.90      0.89        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.87      0.87      0.87       327\n",
            "         NND       0.80      0.50      0.62         8\n",
            "         NNP       0.84      0.90      0.87       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.82      0.95      0.88        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.83      0.83      0.83        46\n",
            "          VB       0.92      0.85      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.90      0.87      0.88      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.71      0.76        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.67      0.49      0.57        65\n",
            "    B-PERSON       0.86      0.81      0.83       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.56      0.60      0.58        15\n",
            "       I-LOC       0.69      0.89      0.78        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.97      0.98      0.98      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.74      0.74      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/40\n",
            "Train Loss: 0.0154\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.99      0.95      0.97        88\n",
            "          JJ       0.77      0.85      0.81       122\n",
            "          MD       0.90      0.87      0.88        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.90      0.84      0.87       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.82      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.87      0.92      0.89        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.84      0.83      0.84        46\n",
            "          VB       0.90      0.86      0.88       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.82      0.69      0.75        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.66      0.48      0.55        65\n",
            "    B-PERSON       0.83      0.81      0.82       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.56      0.60      0.58        15\n",
            "       I-LOC       0.69      0.89      0.78        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.57      0.67      0.62        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.73      0.74      0.73      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/40\n",
            "Train Loss: 0.0132\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.83      0.80      0.82       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       0.96      1.00      0.98        25\n",
            "          NN       0.92      0.82      0.87       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.82      0.92      0.87       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.86      0.95      0.90        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.80      0.87      0.83        46\n",
            "          VB       0.88      0.90      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.89      0.89      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.71      0.76        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.77      0.46      0.58        65\n",
            "    B-PERSON       0.79      0.85      0.82       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.59      0.67      0.62        15\n",
            "       I-LOC       0.67      0.89      0.77        55\n",
            "       I-ORG       0.58      0.54      0.56        13\n",
            "    I-PERSON       0.57      0.67      0.62        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.74      0.75      0.74      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/40\n",
            "Train Loss: 0.0192\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      1.00      1.00        20\n",
            "          CD       0.97      0.97      0.97        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.98      0.95      0.97        88\n",
            "          JJ       0.86      0.80      0.83       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.89      0.85      0.87       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.82      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.89      0.95      0.92        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.77      0.87      0.82        46\n",
            "          VB       0.90      0.89      0.90       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.90      1570\n",
            "   macro avg       0.92      0.89      0.90      1570\n",
            "weighted avg       0.90      0.90      0.90      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.64      0.82      0.72        34\n",
            "       B-ORG       0.73      0.46      0.57        65\n",
            "    B-PERSON       0.78      0.86      0.82       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.67      0.89      0.77        55\n",
            "       I-ORG       0.58      0.54      0.56        13\n",
            "    I-PERSON       0.57      0.67      0.62        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.74      0.75      0.74      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/40\n",
            "Train Loss: 0.0126\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.97      0.97      0.97        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.98      0.95      0.97        88\n",
            "          JJ       0.84      0.81      0.82       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.89      0.84      0.86       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.82      0.90      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.88      0.95      0.91        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.78      0.87      0.82        46\n",
            "          VB       0.90      0.89      0.90       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.90      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.90      0.90      0.90      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.64      0.82      0.72        34\n",
            "       B-ORG       0.77      0.46      0.58        65\n",
            "    B-PERSON       0.81      0.86      0.83       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.67      0.89      0.77        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.75      0.75      2241\n",
            "weighted avg       0.94      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/40\n",
            "Train Loss: 0.0134\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.97      0.97      0.97        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.82      0.84      0.83       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.90      0.83      0.86       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.81      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.88      0.94      0.91        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.91      0.98      0.94        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.82      0.87      0.84        46\n",
            "          VB       0.90      0.88      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.89      0.89      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.64      0.82      0.72        34\n",
            "       B-ORG       0.77      0.46      0.58        65\n",
            "    B-PERSON       0.81      0.86      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.66      0.89      0.76        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.98      0.97      0.98      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.75      0.75      2241\n",
            "weighted avg       0.94      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/40\n",
            "Train Loss: 0.0119\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      1.00      1.00        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.98      0.95      0.97        88\n",
            "          JJ       0.81      0.83      0.82       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.89      0.83      0.86       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.82      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.88      0.95      0.91        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.80      0.87      0.83        46\n",
            "          VB       0.90      0.88      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.64      0.82      0.72        34\n",
            "       B-ORG       0.76      0.54      0.63        65\n",
            "    B-PERSON       0.83      0.85      0.84       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.67      0.89      0.77        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.77      0.76      0.75      2241\n",
            "weighted avg       0.94      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/40\n",
            "Train Loss: 0.0133\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.85      0.82      0.83       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.89      0.83      0.86       327\n",
            "         NND       0.83      0.62      0.71         8\n",
            "         NNP       0.82      0.91      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.88      0.96      0.92        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.80      0.87      0.83        46\n",
            "          VB       0.90      0.89      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.90      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.90      0.90      0.90      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.65      0.82      0.73        34\n",
            "       B-ORG       0.77      0.46      0.58        65\n",
            "    B-PERSON       0.80      0.86      0.83       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.67      0.89      0.77        55\n",
            "       I-ORG       0.58      0.54      0.56        13\n",
            "    I-PERSON       0.73      0.67      0.70        12\n",
            "           O       0.98      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.76      0.75      0.75      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/40\n",
            "Train Loss: 0.0112\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.95      1.00      0.98        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.83      0.82      0.82       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.90      0.83      0.87       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.83      0.91      0.87       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.88      0.96      0.91        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.81      0.85      0.83        46\n",
            "          VB       0.90      0.88      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.90      1570\n",
            "   macro avg       0.91      0.89      0.89      1570\n",
            "weighted avg       0.90      0.90      0.90      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.67      0.82      0.74        34\n",
            "       B-ORG       0.80      0.51      0.62        65\n",
            "    B-PERSON       0.84      0.85      0.85       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.60      0.60      0.60        15\n",
            "       I-LOC       0.66      0.89      0.76        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.77      0.75      0.75      2241\n",
            "weighted avg       0.94      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/40\n",
            "Train Loss: 0.0160\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.95      0.97        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.82      0.79      0.80       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.91      0.83      0.87       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.81      0.92      0.86       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       1.00      0.94      0.97        53\n",
            "          RB       0.84      0.97      0.90        95\n",
            "          RP       1.00      0.80      0.89        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.76      0.83      0.79        46\n",
            "          VB       0.90      0.88      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.89      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.90      0.89      0.89      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.67      0.82      0.74        34\n",
            "       B-ORG       0.76      0.43      0.55        65\n",
            "    B-PERSON       0.81      0.80      0.80       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.62      0.67      0.65        15\n",
            "       I-LOC       0.69      0.89      0.78        55\n",
            "       I-ORG       0.50      0.54      0.52        13\n",
            "    I-PERSON       0.67      0.83      0.74        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.75      0.76      0.74      2241\n",
            "weighted avg       0.93      0.93      0.92      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/40\n",
            "Train Loss: 0.0204\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.95      0.97        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.97      0.95      0.96        88\n",
            "          JJ       0.82      0.83      0.82       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.90      0.84      0.87       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.83      0.91      0.87       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.88      0.96      0.91        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.76      0.85      0.80        46\n",
            "          VB       0.91      0.88      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.90      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.90      0.90      0.90      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.68      0.82      0.75        34\n",
            "       B-ORG       0.78      0.48      0.59        65\n",
            "    B-PERSON       0.84      0.85      0.85       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.60      0.60      0.60        15\n",
            "       I-LOC       0.68      0.89      0.77        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.77      0.75      0.75      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/40\n",
            "Train Loss: 0.0111\n",
            "Validation Loss: 0.0000\n",
            "Validation POS Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.95      0.97        20\n",
            "          CD       0.95      0.97      0.96        38\n",
            "          DT       0.72      0.87      0.79        15\n",
            "          FW       1.00      0.50      0.67         4\n",
            "          IN       0.95      0.95      0.95        88\n",
            "          JJ       0.82      0.82      0.82       122\n",
            "          MD       0.90      0.90      0.90        30\n",
            "         NEG       1.00      1.00      1.00        25\n",
            "          NN       0.90      0.84      0.87       327\n",
            "         NND       0.86      0.75      0.80         8\n",
            "         NNP       0.83      0.92      0.87       222\n",
            "          OD       0.86      1.00      0.92         6\n",
            "          PR       1.00      0.84      0.91        25\n",
            "         PRP       0.98      0.94      0.96        53\n",
            "          RB       0.87      0.96      0.91        95\n",
            "          RP       0.92      0.80      0.86        15\n",
            "          SC       0.93      0.98      0.95        41\n",
            "         SYM       0.95      0.90      0.92        39\n",
            "          UH       0.78      0.85      0.81        46\n",
            "          VB       0.91      0.88      0.89       206\n",
            "          WH       0.92      0.85      0.88        13\n",
            "           Z       0.99      0.99      0.99       132\n",
            "\n",
            "    accuracy                           0.90      1570\n",
            "   macro avg       0.91      0.88      0.89      1570\n",
            "weighted avg       0.90      0.90      0.90      1570\n",
            "\n",
            "Validation NER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     B-EVENT       0.75      1.00      0.86         6\n",
            "       B-GPE       0.83      0.73      0.78        48\n",
            "       B-LOC       0.68      0.82      0.75        34\n",
            "       B-ORG       0.79      0.48      0.60        65\n",
            "    B-PERSON       0.84      0.85      0.85       183\n",
            "     I-EVENT       1.00      0.67      0.80         3\n",
            "       I-GPE       0.60      0.60      0.60        15\n",
            "       I-LOC       0.67      0.89      0.77        55\n",
            "       I-ORG       0.54      0.54      0.54        13\n",
            "    I-PERSON       0.80      0.67      0.73        12\n",
            "           O       0.97      0.97      0.97      1807\n",
            "\n",
            "    accuracy                           0.93      2241\n",
            "   macro avg       0.77      0.75      0.75      2241\n",
            "weighted avg       0.93      0.93      0.93      2241\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class TokenClassificationDataset(Dataset):\n",
        "    def __init__(self, encodings, pos_labels, ner_labels):\n",
        "        self.encodings = encodings\n",
        "        self.pos_labels = pos_labels\n",
        "        self.ner_labels = ner_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pos_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels_pos'] = torch.tensor(self.pos_labels[idx])\n",
        "        item['labels_ner'] = torch.tensor(self.ner_labels[idx])\n",
        "        return item\n",
        "\n",
        "# Prepare datasets and dataloaders\n",
        "train_dataset = TokenClassificationDataset(encoded_train, aligned_pos_labels_train, aligned_ner_labels_train)\n",
        "val_dataset   = TokenClassificationDataset(encoded_val, aligned_pos_labels_val, aligned_ner_labels_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer & Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "epochs = 40\n",
        "total_steps = len(train_loader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Training and Validation Loop\n",
        "def train_epoch(model, loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in loader:\n",
        "        optimizer.zero_grad()\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            labels_pos=batch['labels_pos'],\n",
        "            labels_ner=batch['labels_ner']\n",
        "        )\n",
        "        loss = outputs['loss']\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, device, pos_label_map, ner_label_map):\n",
        "    model.eval()\n",
        "    all_preds_pos, all_labels_pos = [], []\n",
        "    all_preds_ner, all_labels_ner = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for batch in loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask']\n",
        "            )\n",
        "            logits_pos = outputs['logits_pos'].argmax(-1).cpu().numpy()\n",
        "            logits_ner = outputs['logits_ner'].argmax(-1).cpu().numpy()\n",
        "            labels_pos = batch['labels_pos'].cpu().numpy()\n",
        "            labels_ner = batch['labels_ner'].cpu().numpy()\n",
        "\n",
        "            val_loss += outputs['loss']\n",
        "\n",
        "            for lp, pp in zip(labels_pos, logits_pos):\n",
        "                mask = lp != -100\n",
        "                all_labels_pos.extend(lp[mask].tolist())\n",
        "                all_preds_pos.extend(pp[mask].tolist())\n",
        "            for ln, pn in zip(labels_ner, logits_ner):\n",
        "                mask = ln != -100\n",
        "                all_labels_ner.extend(ln[mask].tolist())\n",
        "                all_preds_ner.extend(pn[mask].tolist())\n",
        "        avg_val_loss = val_loss / len(loader)\n",
        "\n",
        "    all_labels_pos = [pos_label_map[label] for label in all_labels_pos]\n",
        "    all_preds_pos = [pos_label_map[pred] for pred in all_preds_pos]\n",
        "    all_labels_ner = [ner_label_map[label] for label in all_labels_ner]\n",
        "    all_preds_ner = [ner_label_map[pred] for pred in all_preds_ner]\n",
        "\n",
        "    report_pos = classification_report(all_labels_pos, all_preds_pos)\n",
        "    report_ner = classification_report(all_labels_ner, all_preds_ner)\n",
        "    return all_preds_pos, all_preds_ner, report_pos, report_ner, avg_val_loss\n",
        "\n",
        "# Running training\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
        "    preds_pos, preds_ner, val_report_pos, val_report_ner, val_loss = evaluate(model, val_loader, device, pos_id2label, ner_id2label)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "    print(\"Validation POS Classification Report:\\n\", val_report_pos)\n",
        "    print(\"Validation NER Classification Report:\\n\", val_report_ner)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIk2g4541IZp",
        "outputId": "7fe2dbbf-41f6-4266-c3af-0f2a390c37a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[969, 970, 1110, 1381]\n",
            "UH\tNN\t"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        }
      ],
      "source": [
        "all_labels_pos = []\n",
        "all_labels_ner = []\n",
        "\n",
        "for batch in val_loader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    labels_pos = batch['labels_pos'].cpu().numpy()\n",
        "    labels_ner = batch['labels_ner'].cpu().numpy()\n",
        "\n",
        "    for lp in labels_pos:  # Iterate directly over the elements of labels_pos\n",
        "        mask = lp != -100\n",
        "        if mask.any():  # Check if there are any valid elements\n",
        "            all_labels_pos.extend(lp[mask].tolist())\n",
        "\n",
        "\n",
        "    for ln in labels_ner:  # Iterate directly over the elements of labels_ner\n",
        "        mask = ln != -100\n",
        "        if mask.any():  # Check if there are any valid elements\n",
        "            all_labels_ner.extend(ln[mask].tolist())\n",
        "\n",
        "all_labels_pos = [pos_id2label[label] for label in all_labels_pos]\n",
        "all_labels_ner = [ner_id2label[label] for label in all_labels_ner]\n",
        "\n",
        "store_idx = []\n",
        "label_find = 'FW'\n",
        "\n",
        "for idx, label in enumerate(all_labels_pos):\n",
        "    if label == label_find:\n",
        "        store_idx.append(idx)\n",
        "\n",
        "print(store_idx)\n",
        "\n",
        "for idx in store_idx:\n",
        "    if preds_pos[idx] != label_find:\n",
        "        print(preds_pos[idx], end='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B67A9RXAYPWA"
      },
      "source": [
        "## 4.3 Inference / Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8C8i_XV-WO_"
      },
      "outputs": [],
      "source": [
        "class InferenceTokenClassificationDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Tp6jySz-i1k"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(InferenceTokenClassificationDataset(encoded_val), batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z76Bl4ksAwYP"
      },
      "outputs": [],
      "source": [
        "def predict(model, loader, device, pos_id2label, ner_id2label):\n",
        "    model.eval()\n",
        "    all_pos_preds = []\n",
        "    all_ner_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask']\n",
        "            )\n",
        "\n",
        "            # Get predictions\n",
        "            logits_pos = outputs['logits_pos'].argmax(-1).cpu().numpy()\n",
        "            logits_ner = outputs['logits_ner'].argmax(-1).cpu().numpy()\n",
        "            labels_pos = batch['labels_pos'].cpu().numpy()\n",
        "            labels_ner = batch['labels_ner'].cpu().numpy()\n",
        "\n",
        "            for lp, pp, ln, pn in zip(labels_pos, logits_pos, labels_ner, logits_ner):\n",
        "                pos_preds = []\n",
        "                ner_preds = []\n",
        "\n",
        "                for lpos, ppos, lner, pner in zip(lp, pp, ln, pn):\n",
        "                    if lpos != -100:  # ignore padding / subword tokens\n",
        "                        pos_preds.append(pos_id2label[ppos])\n",
        "                        ner_preds.append(ner_id2label[pner])\n",
        "\n",
        "                all_pos_preds.append(pos_preds)\n",
        "                all_ner_preds.append(ner_preds)\n",
        "\n",
        "    return all_pos_preds, all_ner_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W46Azed5ka-",
        "outputId": "f079be85-d7b2-4b7d-d383-b7d143142b40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-6153dee57760>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        }
      ],
      "source": [
        "results_pos_preds, results_ner_preds = predict(model, val_loader, device, pos_id2label, ner_id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQajCdXx-xJ8",
        "outputId": "5fb417f1-9bfc-4c23-99da-33b83ecc9101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['NNP', 'Z', 'NEG', 'VB', 'NNP', 'RB', 'VB', 'NNP', 'Z', 'NNP', 'Z', 'DT', 'VB', 'Z']\n",
            "['B-ORG', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-PERSON', 'O', 'B-PERSON', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "print(results_pos_preds[0])\n",
        "print(results_ner_preds[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBG0aatsYTT5"
      },
      "source": [
        "## 4.5 Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO2SuAmMYTT6",
        "outputId": "0b1dde30-1255-44a0-c92a-eb9c47f2a28b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Models/checked1/xlmroberta-multitask-tokenclf-nomisc/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Models/checked1/xlmroberta-multitask-tokenclf-nomisc/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Models/checked1/xlmroberta-multitask-tokenclf-nomisc/sentencepiece.bpe.model',\n",
              " '/content/drive/MyDrive/Models/checked1/xlmroberta-multitask-tokenclf-nomisc/added_tokens.json',\n",
              " '/content/drive/MyDrive/Models/checked1/xlmroberta-multitask-tokenclf-nomisc/tokenizer.json')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the fine-tuned model\n",
        "model.save_pretrained('/content/drive/MyDrive/Models/checked1/xlmroberta-multitask-tokenclf')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/Models/checked1/xlmroberta-multitask-tokenclf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0KIr5LmYnyy"
      },
      "source": [
        "# 5. CRF Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ0QTc_MV1xL"
      },
      "source": [
        "## 5.0 Tokenizer and Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "_vA5SqPm2u8Y",
        "outputId": "c64a361a-fe6b-4f5f-b51d-7bc2110f16bc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f559e9a5b2f6465398fd64230fa79f33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b84132267dee4fa8916d453f5b8a32ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d04e3524cfbd4743b30387b5cbbfbc7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec8bac3d88704a9d8b8fca50d5e7372c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import XLMRobertaTokenizerFast\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer_crf = XLMRobertaTokenizerFast.from_pretrained('xlm-roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6eZ5cuNSS4B"
      },
      "outputs": [],
      "source": [
        "def align_labels_crf(encoding, pos_labels, ner_labels, pos_label2id, ner_label2id):\n",
        "    all_pos, all_ner = [], []\n",
        "\n",
        "    for idx in range(len(encoding['input_ids'])):\n",
        "        word_ids = encoding.word_ids(batch_index=idx)\n",
        "        pos_seq, ner_seq = [], []\n",
        "        words_pos = pos_labels[idx] if idx < len(pos_labels) else []\n",
        "        words_ner = ner_labels[idx] if idx < len(ner_labels) else []\n",
        "        w_idx = 0\n",
        "\n",
        "        # keep track of the *string* of the current word’s entity tag\n",
        "        current_ent = None\n",
        "\n",
        "        for token_idx, word_id in enumerate(word_ids):\n",
        "          try:\n",
        "            # 1) Special / padding tokens\n",
        "              if word_id is None:\n",
        "                  pos_seq.append(-100)\n",
        "                  ner_seq.append(-100)\n",
        "                  current_ent = None\n",
        "                  continue\n",
        "\n",
        "              # 2) First subword of a word\n",
        "              is_first = (token_idx == 0) or (word_id != word_ids[token_idx-1])\n",
        "              if is_first:\n",
        "                  # POS as before\n",
        "                  if w_idx < len(words_pos):\n",
        "                      pos_tag = words_pos[w_idx]\n",
        "                      if isinstance(pos_tag, list):\n",
        "                          pos_tag = pos_tag[0] if pos_tag else None\n",
        "                      pos_seq.append(pos_label2id.get(pos_tag, -100))\n",
        "                  else:\n",
        "                      pos_seq.append(-100)\n",
        "\n",
        "                  # NER: take the word-level tag\n",
        "                  if w_idx < len(words_ner):\n",
        "                      ner_tag = words_ner[w_idx]\n",
        "                      if isinstance(ner_tag, list):\n",
        "                          ner_tag = ner_tag[0] if ner_tag else None\n",
        "                      # store for continuations\n",
        "                      current_ent = ner_tag\n",
        "                      ner_seq.append(ner_label2id[ner_tag])\n",
        "                  else:\n",
        "                      # no word-level tag\n",
        "                      current_ent = None\n",
        "                      ner_seq.append(-100)\n",
        "\n",
        "                  w_idx += 1\n",
        "\n",
        "              # 3) Continuation subword\n",
        "              else:\n",
        "                  pos_seq.append(-100)\n",
        "\n",
        "                  if current_ent is None or current_ent == \"O\":\n",
        "                      # word wasn’t an entity or wasn’t tagged\n",
        "                      ner_seq.append(ner_label2id[\"O\"])\n",
        "                  else:\n",
        "                      # word was B-ENT or I-ENT, so continue with I-ENT\n",
        "                      ent_type = current_ent.split(\"-\", 1)[-1]  # e.g. \"PER\"\n",
        "                      cont_tag = \"I-\" + ent_type\n",
        "                      ner_seq.append(ner_label2id[cont_tag])\n",
        "          except KeyError:\n",
        "            print(f\"Index {token_idx}\")\n",
        "            raise\n",
        "\n",
        "        all_pos.append(pos_seq)\n",
        "        all_ner.append(ner_seq)\n",
        "\n",
        "    return all_pos, all_ner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NANT5fhm2Cjk"
      },
      "outputs": [],
      "source": [
        "encoded_train = tokenizer_crf(\n",
        "    train_set['tokens'].tolist(),\n",
        "    is_split_into_words=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "encoded_val = tokenizer_crf(\n",
        "    val_set['tokens'].tolist(),\n",
        "    is_split_into_words=True,\n",
        "    return_offsets_mapping=True,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "aligned_pos_labels_train, aligned_ner_labels_train = align_labels_crf(\n",
        "    encoded_train,\n",
        "    train_set['pos_labels'].tolist(),\n",
        "    train_set['ner_labels'].tolist(),\n",
        "    pos_label2id,\n",
        "    ner_label2id\n",
        ")\n",
        "\n",
        "aligned_pos_labels_val, aligned_ner_labels_val = align_labels_crf(\n",
        "    encoded_val,\n",
        "    val_set['pos_labels'].tolist(),\n",
        "    val_set['ner_labels'].tolist(),\n",
        "    pos_label2id,\n",
        "    ner_label2id\n",
        ")\n",
        "\n",
        "# Get the device from encoded['input_ids']\n",
        "device = encoded_train['input_ids'].device\n",
        "\n",
        "encoded_pos_labels_train = torch.tensor(aligned_pos_labels_train).to(device)\n",
        "encoded_ner_labels_train = torch.tensor(aligned_ner_labels_train).to(device)\n",
        "\n",
        "encoded_pos_labels_val = torch.tensor(aligned_pos_labels_val).to(device)\n",
        "encoded_ner_labels_val = torch.tensor(aligned_ner_labels_val).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kC8ma0J-qHO",
        "outputId": "3afd3292-58af-44fb-b861-f7f0fb66ce53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<s>',\n",
              " '▁cara',\n",
              " '▁ke',\n",
              " '▁blok',\n",
              " '▁m',\n",
              " '▁pake',\n",
              " '▁trans',\n",
              " 'um',\n",
              " '▁dari',\n",
              " '▁bunda',\n",
              " 'ran',\n",
              " '▁hi',\n",
              " '▁1',\n",
              " '▁',\n",
              " '.',\n",
              " '▁naik',\n",
              " '▁mrt',\n",
              " '▁dari',\n",
              " '▁bund',\n",
              " '▁hi',\n",
              " '▁turun',\n",
              " '▁duk',\n",
              " 'uh',\n",
              " '▁atas',\n",
              " '▁2',\n",
              " '▁',\n",
              " '.',\n",
              " '▁dari',\n",
              " '▁duk',\n",
              " 'uh',\n",
              " '▁atas',\n",
              " '▁jalan',\n",
              " '▁ke',\n",
              " '▁st',\n",
              " '▁b',\n",
              " 'ni',\n",
              " '▁city',\n",
              " '▁terus',\n",
              " '▁naik',\n",
              " '▁kr',\n",
              " 'l',\n",
              " '▁bas',\n",
              " 'o',\n",
              " 'etta',\n",
              " '▁turun',\n",
              " '▁ra',\n",
              " 'wa',\n",
              " '▁bu',\n",
              " 'aya',\n",
              " '▁3',\n",
              " '▁',\n",
              " '.',\n",
              " '▁dari',\n",
              " '▁ra',\n",
              " 'wa',\n",
              " '▁bu',\n",
              " 'aya',\n",
              " '▁naik',\n",
              " '▁kr',\n",
              " 'l',\n",
              " '▁arah',\n",
              " '▁du',\n",
              " 'ri',\n",
              " '▁turun',\n",
              " '▁gro',\n",
              " 'gol',\n",
              " '▁4',\n",
              " '▁',\n",
              " '.',\n",
              " '▁dari',\n",
              " '▁gro',\n",
              " 'gol',\n",
              " '▁naik',\n",
              " '▁trans',\n",
              " 'ja',\n",
              " 'karta',\n",
              " '▁arah',\n",
              " '▁pin',\n",
              " 'ang',\n",
              " '▁ran',\n",
              " 'ti',\n",
              " '▁turun',\n",
              " '▁pan',\n",
              " 'cor',\n",
              " 'an',\n",
              " '</s>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer_crf.convert_ids_to_tokens(encoded_train['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH_wQ5sUAVPK",
        "outputId": "c26a702d-b49a-4ca8-b581-075500289d46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-100,    0,    0,    0,    0,    0,    0,    0, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_ner_labels_train[103]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdpW6yvm-uOI",
        "outputId": "3e341a3e-6ce1-43ee-bf79-dd623e85b4d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-100,    9,    5,   10,   10,   19,    9, -100,    5,   10, -100,   10,\n",
              "           2,   21, -100,   19,    9,    5,   10,   10,   19,   10, -100,   10,\n",
              "           2,   21, -100,    5,   10, -100,   10,   19,    5,   10,   10, -100,\n",
              "          10,   14,   19,    9, -100,   10, -100, -100,   19,   10, -100,   10,\n",
              "        -100,    2,   21, -100,    5,   10, -100,   10, -100,   19,    9, -100,\n",
              "           9,   10, -100,   19,   10, -100,    2,   21, -100,    5,   10, -100,\n",
              "           5,   10, -100, -100,    9,   10, -100,   10, -100,   19,   10, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "        -100, -100, -100, -100, -100, -100, -100])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_pos_labels_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSfL3alZY6PI"
      },
      "source": [
        "## 5.1 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "016nD-h_Y32K",
        "outputId": "58754351-3aea-457a-8fb0-763001e0ea3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-crf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yJ2l_yRpaIY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaModel, XLMRobertaPreTrainedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "rjvp6w5VXtP3",
        "outputId": "109d7b19-d771-4308-d9a1-da0acc58be57"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-21-4c5bb8432715>, line 39)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-4c5bb8432715>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    loss += loss_fct(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "from torchcrf import CRF\n",
        "import torch.nn as nn\n",
        "\n",
        "class XLMRobertaForMultiTaskTokenClassificationWithCRF(XLMRobertaPreTrainedModel):\n",
        "    def __init__(self, config, num_pos_labels, num_ner_labels):\n",
        "        super().__init__(config)\n",
        "        assert num_pos_labels > 0 and num_ner_labels > 0\n",
        "        self.num_pos_labels = num_pos_labels\n",
        "        self.num_ner_labels = num_ner_labels\n",
        "\n",
        "        self.roberta = XLMRobertaModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.classifier_pos = nn.Linear(config.hidden_size, num_pos_labels)\n",
        "        self.classifier_ner = nn.Linear(config.hidden_size, num_ner_labels)\n",
        "\n",
        "        self.crf = CRF(num_tags=num_ner_labels, batch_first=True)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids=None,\n",
        "                attention_mask=None,\n",
        "                labels_pos=None,\n",
        "                labels_ner=None):\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask)\n",
        "        seq_out = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        # POS\n",
        "        logits_pos = self.classifier_pos(seq_out)\n",
        "        loss = 0.0\n",
        "        # if labels_pos is not None:\n",
        "        #     loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "        #     loss += loss_fct(\n",
        "        #         logits_pos.view(-1, self.num_pos_labels),\n",
        "        #         labels_pos.view(-1)\n",
        "        #     )\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "        loss += loss_fct(\n",
        "            logits_pos.view(-1, self.num_pos_labels),\n",
        "            labels_pos.view(-1)\n",
        "        )\n",
        "            # print(loss)\n",
        "\n",
        "        # NER with CRF\n",
        "        emissions_ner = self.classifier_ner(seq_out)\n",
        "\n",
        "        # if labels_ner is not None:\n",
        "        #     mask = attention_mask.bool()\n",
        "        #     # labels_ner already has no -100\n",
        "        #     log_likelihood = self.crf(\n",
        "        #         emissions_ner,\n",
        "        #         labels_ner,\n",
        "        #         mask=mask,\n",
        "        #         reduction='mean'\n",
        "        #     )\n",
        "        #     # print(-log_likelihood)\n",
        "        #     ner_alpha = 0.3\n",
        "        #     loss += -log_likelihood * ner_alpha\n",
        "\n",
        "\n",
        "        mask = attention_mask.bool()\n",
        "        # labels_ner already has no -100\n",
        "        log_likelihood = self.crf(\n",
        "            emissions_ner,\n",
        "            labels_ner,\n",
        "            mask=mask,\n",
        "            reduction='mean'\n",
        "        )\n",
        "        # print(-log_likelihood)\n",
        "        ner_alpha = 0.3\n",
        "        loss += -log_likelihood * ner_alpha\n",
        "\n",
        "\n",
        "        # Decode for inference\n",
        "        ner_preds = None\n",
        "        if labels_ner is None:\n",
        "            mask = attention_mask.bool()\n",
        "            ner_preds = self.crf.decode(emissions_ner, mask=mask)\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"logits_pos\": logits_pos,\n",
        "            \"emissions_ner\": emissions_ner,\n",
        "            \"predictions_ner\": ner_preds,\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y_s7MkhZI7z"
      },
      "outputs": [],
      "source": [
        "ner_label2id[\"PAD\"] = 11\n",
        "ner_id2label[11] = \"PAD\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "886f2547505c4ff19313cb0a349ee092"
          ]
        },
        "id": "kDVWLcS0W-g3",
        "outputId": "d3acc0f7-009a-4f14-a631-f30de913d9a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "886f2547505c4ff19313cb0a349ee092",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import XLMRobertaConfig\n",
        "from transformers import XLMRobertaModel\n",
        "\n",
        "config = XLMRobertaConfig.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Specify the number of POS and NER labels\n",
        "num_pos_labels = len(pos_label2id)  # Example: Adjust based on your POS label set\n",
        "num_ner_labels = len(ner_label2id)   # Example: Adjust based on your NER label set\n",
        "\n",
        "# Instantiate the model\n",
        "model = XLMRobertaForMultiTaskTokenClassificationWithCRF(config, num_pos_labels, num_ner_labels)\n",
        "model.roberta = XLMRobertaModel.from_pretrained('xlm-roberta-base', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rWeFudNBHR1k",
        "outputId": "0afc77df-e006-4a29-acd1-8d7a5433b8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRF transitions shape: torch.Size([12, 12])\n",
            "Any NaN? False\n",
            "Any +Inf? False\n",
            "Any -Inf? False\n",
            "Transition stats: -0.09962993860244751 0.09843508154153824\n"
          ]
        }
      ],
      "source": [
        "# Immediately after model = XLMRobertaForMultiTaskTokenClassificationWithCRF(...)\n",
        "transitions = model.crf.transitions  # this is a nn.Parameter of shape (num_tags, num_tags)\n",
        "print(\"CRF transitions shape:\", transitions.shape)\n",
        "print(\"Any NaN?\", torch.isnan(transitions).any().item())\n",
        "print(\"Any +Inf?\", torch.isposinf(transitions).any().item())\n",
        "print(\"Any -Inf?\", torch.isneginf(transitions).any().item())\n",
        "print(\"Transition stats:\", transitions.min().item(), transitions.max().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A8Bf8ksmwIGz",
        "outputId": "bf9a4adc-e4d7-4534-e31f-f4d656a3ad64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0700,  0.0490,  0.0394, -0.0628,  0.0106, -0.0305,  0.0506,  0.0856,\n",
            "         -0.0329, -0.0525, -0.0779,  0.0610],\n",
            "        [ 0.0649,  0.0618, -0.0753,  0.0555, -0.0852,  0.0114, -0.0132,  0.0844,\n",
            "         -0.0854, -0.0618,  0.0154, -0.0187],\n",
            "        [-0.0836,  0.0190, -0.0866, -0.0082, -0.0160,  0.0251, -0.0572,  0.0956,\n",
            "          0.0239,  0.0475, -0.0801,  0.0046],\n",
            "        [-0.0664,  0.0758,  0.0770,  0.0569, -0.0524, -0.0587, -0.0198, -0.0669,\n",
            "         -0.0027,  0.0130,  0.0571,  0.0378],\n",
            "        [ 0.0984,  0.0695,  0.0197, -0.0934, -0.0324,  0.0209, -0.0177,  0.0069,\n",
            "          0.0139,  0.0109,  0.0848,  0.0472],\n",
            "        [-0.0125,  0.0496,  0.0459, -0.0006, -0.0707, -0.0173, -0.0996, -0.0430,\n",
            "          0.0932, -0.0126,  0.0607,  0.0646],\n",
            "        [-0.0439,  0.0609,  0.0751, -0.0838, -0.0863,  0.0449,  0.0808,  0.0183,\n",
            "         -0.0946,  0.0269, -0.0030, -0.0169],\n",
            "        [-0.0227, -0.0989,  0.0273,  0.0128, -0.0693, -0.0521, -0.0772,  0.0459,\n",
            "          0.0175, -0.0486,  0.0464,  0.0017],\n",
            "        [ 0.0117, -0.0137, -0.0285,  0.0767,  0.0790, -0.0560, -0.0612, -0.0640,\n",
            "         -0.0594,  0.0423,  0.0024,  0.0450],\n",
            "        [-0.0320, -0.0370,  0.0826,  0.0402,  0.0133, -0.0465, -0.0046, -0.0340,\n",
            "          0.0671,  0.0927, -0.0184,  0.0667],\n",
            "        [-0.0674, -0.0153, -0.0661, -0.0946, -0.0615,  0.0054,  0.0021,  0.0773,\n",
            "          0.0756, -0.0475,  0.0206, -0.0431],\n",
            "        [-0.0497, -0.0810, -0.0557,  0.0321,  0.0871, -0.0979,  0.0512, -0.0237,\n",
            "         -0.0633, -0.0964,  0.0297,  0.0254]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "transitions = model.crf.transitions\n",
        "print(transitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vb99wx0e5z50"
      },
      "outputs": [],
      "source": [
        "num_tags = model.crf.num_tags\n",
        "\n",
        "legal = torch.ones(num_tags, num_tags, dtype=torch.bool)\n",
        "\n",
        "b_labels = [nid for lab, nid in ner_label2id.items() if lab.startswith(\"B-\")]\n",
        "i_labels = [nid for lab, nid in ner_label2id.items() if lab.startswith(\"I-\")]\n",
        "\n",
        "# 2) Forbid I-X → I-Y when X != Y\n",
        "for i in i_labels:\n",
        "    for j in i_labels:\n",
        "        if i != j:\n",
        "            legal[i, j] = False\n",
        "\n",
        "# 3) Forbid B-X → I-Y when X != Y (only allow B-X→I-X)\n",
        "for b in b_labels:\n",
        "    b_ent = ner_id2label[b].split(\"-\", 1)[1]\n",
        "    for j in i_labels:\n",
        "        j_ent = ner_id2label[j].split(\"-\", 1)[1]\n",
        "        if b_ent != j_ent:\n",
        "            legal[b, j] = False\n",
        "\n",
        "# 4) Forbid O → I-X entirely\n",
        "o_id = ner_label2id[\"O\"]\n",
        "for j in i_labels:\n",
        "    legal[o_id, j] = False\n",
        "\n",
        "for j in [ner_label2id['I-LOC'], ner_label2id['I-PERSON'], ner_label2id['I-ORG'], ner_label2id['I-EVENT'], ner_label2id['I-GPE']]:\n",
        "    legal[ner_label2id['PAD']][j] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-jKzSwOELKPx",
        "outputId": "05d4244f-1997-4fec-f201-0d1980320377"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ True,  True, False,  True, False,  True, False,  True, False,  True,\n",
              "         False,  True],\n",
              "        [ True,  True,  True,  True, False,  True, False,  True, False,  True,\n",
              "         False,  True],\n",
              "        [ True,  True,  True,  True, False,  True, False,  True, False,  True,\n",
              "         False,  True],\n",
              "        [ True,  True, False,  True,  True,  True, False,  True, False,  True,\n",
              "         False,  True],\n",
              "        [ True,  True, False,  True,  True,  True, False,  True, False,  True,\n",
              "         False,  True],\n",
              "        [ True,  True, False,  True, False,  True,  True,  True, False,  True,\n",
              "         False,  True],\n",
              "        [ True,  True, False,  True, False,  True,  True,  True, False,  True,\n",
              "         False,  True],\n",
              "        [ True,  True, False,  True, False,  True, False,  True,  True,  True,\n",
              "         False,  True],\n",
              "        [ True,  True, False,  True, False,  True, False,  True,  True,  True,\n",
              "         False,  True],\n",
              "        [ True,  True, False,  True, False,  True, False,  True, False,  True,\n",
              "          True,  True],\n",
              "        [ True,  True, False,  True, False,  True, False,  True, False,  True,\n",
              "          True,  True],\n",
              "        [ True,  True, False,  True, False,  True, False,  True, False,  True,\n",
              "         False,  True]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "legal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IeA4ppsmqZ2C",
        "outputId": "f746d511-8eab-4f33-b36d-2341a50ed1f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XLMRobertaForMultiTaskTokenClassificationWithCRF(\n",
              "  (roberta): XLMRobertaModel(\n",
              "    (embeddings): XLMRobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): XLMRobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x XLMRobertaLayer(\n",
              "          (attention): XLMRobertaAttention(\n",
              "            (self): XLMRobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): XLMRobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): XLMRobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): XLMRobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): XLMRobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier_pos): Linear(in_features=768, out_features=22, bias=True)\n",
              "  (classifier_ner): Linear(in_features=768, out_features=12, bias=True)\n",
              "  (crf): CRF(num_tags=12)\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.crf.register_buffer(\"transition_mask\", legal.float())\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oz4DX-_-p-qd"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    # transitions is an nn.Parameter of shape (T, T)\n",
        "    mask = model.crf.transition_mask         # 1.0 for legal, 0.0 for illegal\n",
        "    neg_inf = -1e9\n",
        "    model.crf.transitions.data = (\n",
        "        model.crf.transitions.data * mask\n",
        "        + neg_inf * (1.0 - mask)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XkL_593IqWE-",
        "outputId": "3b7ffc5c-fb32-4cc5-af2d-9fbf73291bce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x78875491f390>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ensure the mask is on the same device\n",
        "mask = model.crf.transition_mask.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hook fires during backprop, replacing grad w/ grad*mask\n",
        "model.crf.transitions.register_hook(lambda grad: grad * mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yRhNPLn3LNEP",
        "outputId": "bc26ff83-ffde-424f-a3ac-81cd3180268c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 7.0045e-02,  4.9022e-02, -1.0000e+09, -6.2786e-02, -1.0000e+09,\n",
            "         -3.0547e-02, -1.0000e+09,  8.5650e-02, -1.0000e+09, -5.2504e-02,\n",
            "         -1.0000e+09,  6.0967e-02],\n",
            "        [ 6.4869e-02,  6.1824e-02, -7.5306e-02,  5.5467e-02, -1.0000e+09,\n",
            "          1.1376e-02, -1.0000e+09,  8.4434e-02, -1.0000e+09, -6.1750e-02,\n",
            "         -1.0000e+09, -1.8686e-02],\n",
            "        [-8.3583e-02,  1.9002e-02, -8.6597e-02, -8.2423e-03, -1.0000e+09,\n",
            "          2.5141e-02, -1.0000e+09,  9.5602e-02, -1.0000e+09,  4.7474e-02,\n",
            "         -1.0000e+09,  4.6217e-03],\n",
            "        [-6.6382e-02,  7.5797e-02, -1.0000e+09,  5.6896e-02, -5.2375e-02,\n",
            "         -5.8709e-02, -1.0000e+09, -6.6924e-02, -1.0000e+09,  1.2992e-02,\n",
            "         -1.0000e+09,  3.7795e-02],\n",
            "        [ 9.8435e-02,  6.9486e-02, -1.0000e+09, -9.3417e-02, -3.2431e-02,\n",
            "          2.0862e-02, -1.0000e+09,  6.8535e-03, -1.0000e+09,  1.0924e-02,\n",
            "         -1.0000e+09,  4.7176e-02],\n",
            "        [-1.2506e-02,  4.9611e-02, -1.0000e+09, -5.5933e-04, -1.0000e+09,\n",
            "         -1.7266e-02, -9.9630e-02, -4.3049e-02, -1.0000e+09, -1.2625e-02,\n",
            "         -1.0000e+09,  6.4650e-02],\n",
            "        [-4.3899e-02,  6.0921e-02, -1.0000e+09, -8.3794e-02, -1.0000e+09,\n",
            "          4.4921e-02,  8.0846e-02,  1.8257e-02, -1.0000e+09,  2.6897e-02,\n",
            "         -1.0000e+09, -1.6907e-02],\n",
            "        [-2.2668e-02, -9.8877e-02, -1.0000e+09,  1.2817e-02, -1.0000e+09,\n",
            "         -5.2070e-02, -1.0000e+09,  4.5906e-02,  1.7455e-02, -4.8624e-02,\n",
            "         -1.0000e+09,  1.7086e-03],\n",
            "        [ 1.1681e-02, -1.3707e-02, -1.0000e+09,  7.6724e-02, -1.0000e+09,\n",
            "         -5.6005e-02, -1.0000e+09, -6.4033e-02, -5.9369e-02,  4.2253e-02,\n",
            "         -1.0000e+09,  4.4965e-02],\n",
            "        [-3.1971e-02, -3.7021e-02, -1.0000e+09,  4.0162e-02, -1.0000e+09,\n",
            "         -4.6533e-02, -1.0000e+09, -3.4009e-02, -1.0000e+09,  9.2666e-02,\n",
            "         -1.8401e-02,  6.6721e-02],\n",
            "        [-6.7444e-02, -1.5273e-02, -1.0000e+09, -9.4609e-02, -1.0000e+09,\n",
            "          5.3758e-03, -1.0000e+09,  7.7315e-02, -1.0000e+09, -4.7540e-02,\n",
            "          2.0564e-02, -4.3148e-02],\n",
            "        [-4.9669e-02, -8.0983e-02, -1.0000e+09,  3.2149e-02, -1.0000e+09,\n",
            "         -9.7923e-02, -1.0000e+09, -2.3673e-02, -1.0000e+09, -9.6435e-02,\n",
            "         -1.0000e+09,  2.5436e-02]], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "transitions = model.crf.transitions\n",
        "print(transitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nohCjz0LHk1i",
        "outputId": "d0d5bf9a-b67c-4da8-c7ed-ab822988f727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All buffers look clean. Moving to CUDA…\n",
            "Success!\n"
          ]
        }
      ],
      "source": [
        "# After model instantiation, before model.to(device)\n",
        "import torch\n",
        "\n",
        "bad_buffers = []\n",
        "for name, buf in model.named_buffers():\n",
        "    if not torch.is_floating_point(buf):\n",
        "        continue  # only floats can have NaN/Inf\n",
        "    nan = torch.isnan(buf).any().item()\n",
        "    pinf = torch.isposinf(buf).any().item()\n",
        "    ninf = torch.isneginf(buf).any().item()\n",
        "    if nan or pinf or ninf:\n",
        "        bad_buffers.append((name, nan, pinf, ninf))\n",
        "\n",
        "if bad_buffers:\n",
        "    for name, nan, pinf, ninf in bad_buffers:\n",
        "        print(f\"Buffer {name} has NaN={nan}, +Inf={pinf}, -Inf={ninf}\")\n",
        "    raise RuntimeError(\"Found bad buffers—please reinitialize or investigate.\")\n",
        "else:\n",
        "    print(\"All buffers look clean. Moving to CUDA…\")\n",
        "    model.to('cuda')\n",
        "    print(\"Success!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xVux8mHLHx9f",
        "outputId": "80cd7920-74b5-4f22-b910-d483b2722180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All parameters look clean. Moving to CUDA…\n",
            "Success!\n"
          ]
        }
      ],
      "source": [
        "# After model instantiation, before model.to('cuda')\n",
        "bad_params = []\n",
        "for name, param in model.named_parameters():\n",
        "    if not torch.is_floating_point(param):\n",
        "        continue\n",
        "    nan = torch.isnan(param).any().item()\n",
        "    pinf = torch.isposinf(param).any().item()\n",
        "    ninf = torch.isneginf(param).any().item()\n",
        "    if nan or pinf or ninf:\n",
        "        bad_params.append((name, nan, pinf, ninf))\n",
        "\n",
        "if bad_params:\n",
        "    for name, nan, pinf, ninf in bad_params:\n",
        "        print(f\"Parameter {name} has NaN={nan}, +Inf={pinf}, -Inf={ninf}\")\n",
        "    raise RuntimeError(\"Found bad parameters—please reinitialize or investigate.\")\n",
        "else:\n",
        "    print(\"All parameters look clean. Moving to CUDA…\")\n",
        "    model.to('cuda')\n",
        "    print(\"Success!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oJk_OFdBINdZ",
        "outputId": "69381300-3afa-4ced-8745-43d292b07e5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0+cu124 12.4 0.7.2\n"
          ]
        }
      ],
      "source": [
        "import torch, torchcrf; print(torch.__version__, torch.version.cuda, torchcrf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFIH9yaXdxIF"
      },
      "source": [
        "## 5.2 Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ghxoh0YmsXjb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cXpjNOoWCMFS",
        "outputId": "ae92ef21-2c2b-47e2-8ff9-aa2f68e5be7a"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-d4a87b0058f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_crf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mpreds_pos_crf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_ner_crf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_ner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mner_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_crf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_id2label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mner_id2label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-d4a87b0058f0>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-dcbc6174770c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels_pos, labels_ner)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# labels_ner already has no -100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         log_likelihood = self.crf(\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0memissions_ner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mlabels_ner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcrf/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emissions, tags, mask, reduction)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0memissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "class TokenClassificationDataset(Dataset):\n",
        "    def __init__(self, encodings, pos_labels, ner_labels, pad_ner_id=0):\n",
        "        self.encodings = encodings\n",
        "        self.pos_labels = pos_labels\n",
        "        # replace -100 with pad_ner_id\n",
        "        self.ner_labels = [\n",
        "            [lab if lab >= 0 else pad_ner_id for lab in seq]\n",
        "            for seq in ner_labels\n",
        "        ]\n",
        "        # Sanity check label ranges right at init\n",
        "        num_tags = len(ner_label2id)\n",
        "        for i, seq in enumerate(self.ner_labels):\n",
        "            if min(seq) < 0 or max(seq) >= num_tags:\n",
        "                raise ValueError(f\"NER labels out of range in sequence {i}: {min(seq)} to {max(seq)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pos_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Use as_tensor instead of torch.tensor\n",
        "        item = {key: torch.as_tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels_pos'] = torch.as_tensor(self.pos_labels[idx])\n",
        "        item['labels_ner'] = torch.as_tensor(self.ner_labels[idx])\n",
        "        return item\n",
        "\n",
        "\n",
        "# Instantiate datasets with PAD id for NER\n",
        "pad_ner_id = ner_label2id[\"PAD\"]\n",
        "train_dataset_crf = TokenClassificationDataset(\n",
        "    encodings=encoded_train,\n",
        "    pos_labels=aligned_pos_labels_train,\n",
        "    ner_labels=aligned_ner_labels_train,\n",
        "    pad_ner_id=pad_ner_id\n",
        ")\n",
        "val_dataset_crf = TokenClassificationDataset(\n",
        "    encodings=encoded_val,\n",
        "    pos_labels=aligned_pos_labels_val,\n",
        "    ner_labels=aligned_ner_labels_val,\n",
        "    pad_ner_id=pad_ner_id\n",
        ")\n",
        "\n",
        "train_loader_crf = DataLoader(train_dataset_crf, batch_size=16, shuffle=True)\n",
        "val_loader_crf   = DataLoader(val_dataset_crf, batch_size=16, shuffle=False)\n",
        "\n",
        "\n",
        "optimizer = AdamW([\n",
        "    {'params': model.roberta.parameters(), 'lr': 5e-5},\n",
        "    {'params': model.classifier_pos.parameters(), 'lr' : 5e-5},\n",
        "    {'params': model.classifier_ner.parameters(), 'lr' : 1e-4},\n",
        "    {'params': model.crf.parameters(), 'lr' : 1e-4}\n",
        "])\n",
        "\n",
        "epochs = 70\n",
        "total_steps = len(train_loader_crf) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "def train_epoch(model, loader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in loader:\n",
        "        optimizer.zero_grad()\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(\n",
        "            input_ids=batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            labels_pos=batch['labels_pos'],\n",
        "            labels_ner=batch['labels_ner']\n",
        "        )\n",
        "        loss = outputs['loss']\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader, device, pos_id2label, ner_id2label):\n",
        "    model.eval()\n",
        "    all_labels_pos, all_preds_pos = [], []\n",
        "    all_labels_ner, all_preds_ner = [], []\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                # labels_pos=batch['labels_pos'],\n",
        "                # labels_ner=batch['labels_ner']\n",
        "            )\n",
        "            val_loss += outputs['loss']\n",
        "\n",
        "            # print(model.crf.transitions[:5,:5])  # see your -1e9 entries\n",
        "            # print(\"Using CRF decode?\", outputs.get(\"predictions_ner\") is not None)\n",
        "\n",
        "\n",
        "            # POS\n",
        "            logits_pos = outputs['logits_pos']\n",
        "            preds_pos = logits_pos.argmax(dim=-1).cpu().numpy()\n",
        "            labels_pos = batch['labels_pos'].cpu().numpy()\n",
        "\n",
        "            # NER via CRF decode\n",
        "            # emissions = outputs['emissions_ner']\n",
        "            # mask = batch['attention_mask'].bool()\n",
        "            preds_ner = outputs['predictions_ner']\n",
        "            labels_ner = batch['labels_ner'].cpu().numpy().tolist()\n",
        "\n",
        "            # flatten POS\n",
        "            for lp, pp in zip(labels_pos, preds_pos):\n",
        "                valid = lp != -100  # POS still uses -100\n",
        "                all_labels_pos.extend(lp[valid].tolist())\n",
        "                all_preds_pos.extend(pp[valid].tolist())\n",
        "\n",
        "            # flatten NER (skip PAD if desired)\n",
        "            for ln_seq, pn_seq in zip(labels_ner, preds_ner):\n",
        "                for ln, pn in zip(ln_seq, pn_seq):\n",
        "                    # optionally skip PAD label in metrics\n",
        "                    if ln != pad_ner_id:\n",
        "                        all_labels_ner.append(ln)\n",
        "                        all_preds_ner.append(pn)\n",
        "\n",
        "    avg_val_loss = val_loss / len(loader)\n",
        "\n",
        "    all_labels_pos = [pos_id2label[i] for i in all_labels_pos]\n",
        "    all_preds_pos  = [pos_id2label[i] for i in all_preds_pos]\n",
        "    all_labels_ner = [ner_id2label[i] for i in all_labels_ner]\n",
        "    all_preds_ner  = [ner_id2label[i] for i in all_preds_ner]\n",
        "\n",
        "    report_pos = classification_report(all_labels_pos, all_preds_pos, zero_division=0)\n",
        "    report_ner = classification_report(all_labels_ner, all_preds_ner, zero_division=0)\n",
        "\n",
        "    ner_f1 = f1_score(all_labels_ner, all_preds_ner, average='macro', zero_division=0)\n",
        "\n",
        "    return all_preds_pos, all_preds_ner, report_pos, report_ner, avg_val_loss, ner_f1\n",
        "\n",
        "# Run training\n",
        "\n",
        "highest_f1_ner = 0.0\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss = train_epoch(model, train_loader_crf, optimizer, scheduler, device)\n",
        "    preds_pos_crf, preds_ner_crf, report_pos, report_ner, val_loss, ner_f1 = evaluate(model, val_loader_crf, device, pos_id2label, ner_id2label)\n",
        "    print(f\"Epoch {epoch}/{epochs}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"  Val   Loss: {val_loss:.4f}\")\n",
        "    print(\"  POS Report:\\n\", report_pos)\n",
        "    print(\"  NER Report:\\n\", report_ner)\n",
        "\n",
        "    if ner_f1 > highest_f1_ner:\n",
        "        highest_f1_ner = ner_f1\n",
        "        print(\"Saving model with highest NER F1 score:\", highest_f1_ner, \", from epoch:\", epoch)\n",
        "\n",
        "        model.save_pretrained(f'/content/drive/MyDrive/Models/checkpoints/bestf1/xlmroberta-multitask-tokenclf-withCRF-epoch{}')\n",
        "        tokenizer_crf.save_pretrained(f'/content/drive/MyDrive/Models/checkpoints/bestf1/xlmroberta-multitask-tokenclf-withCRF')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCtd19CNYjzE"
      },
      "source": [
        "## 5.5 Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PGsp_Vl2iK3E"
      },
      "outputs": [],
      "source": [
        "# Save the fine-tuned model\n",
        "model.save_pretrained('/content/drive/MyDrive/Models/checkpoints/final/xlmroberta-multitask-tokenclf-withCRF')\n",
        "tokenizer_crf.save_pretrained('/content/drive/MyDrive/Models/checkpoints/final/xlmroberta-multitask-tokenclf-withCRF')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eraUm8eZ_HAy"
      },
      "outputs": [],
      "source": [
        "all_labels_pos_crf = []\n",
        "all_labels_ner_crf = []\n",
        "all_words = []\n",
        "\n",
        "pad_ner_id = ner_label2id[\"PAD\"]\n",
        "\n",
        "# 1) Iterate batches to collect labels and ids\n",
        "for batch in val_loader_crf:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    input_ids = batch['input_ids'].cpu().numpy()\n",
        "    labels_pos = batch['labels_pos'].cpu().numpy()\n",
        "    labels_ner = batch['labels_ner'].cpu().numpy()\n",
        "\n",
        "    # collect POS labels\n",
        "    for lp in labels_pos:\n",
        "        mask = lp != -100\n",
        "        all_labels_pos_crf.append(lp[mask].tolist())\n",
        "\n",
        "    # collect NER labels\n",
        "    for ln in labels_ner:\n",
        "        seq = [lab for lab in ln if lab != pad_ner_id]\n",
        "        all_labels_ner_crf.append(seq)\n",
        "\n",
        "    # collect the raw token IDs (we’ll convert later)\n",
        "    for seq_ids in input_ids:\n",
        "        all_words.append(seq_ids.tolist())\n",
        "\n",
        "# 2) Convert IDs → tokens\n",
        "#    This gives you subword tokens; e.g. ['▁New', '▁York'] or ['New', 'York']\n",
        "all_word_tokens = [\n",
        "    tokenizer_crf.convert_ids_to_tokens(seq, skip_special_tokens=True)\n",
        "    for seq in all_words\n",
        "]\n",
        "\n",
        "# import re\n",
        "\n",
        "# temp = []\n",
        "\n",
        "# for idx, sen in enumerate(all_word_tokens) :\n",
        "#   store_token = \"\"\n",
        "#   store_sen = []\n",
        "#   for idxT,token in enumerate(sen):\n",
        "#     if re.match(r'^__', token):\n",
        "#       store_token = token.lstrip('_')\n",
        "#     else :\n",
        "#       store_token += token + \" \"\n",
        "\n",
        "#     if idxT == len(sen)-1 or re.match(r'^__', sen[idx+1]):\n",
        "#       store_sen.append(store_token.strip())\n",
        "#       store_token = \"\"\n",
        "\n",
        "#   temp.append(store_sen)\n",
        "\n",
        "# print(temp)\n",
        "\n",
        "\n",
        "\n",
        "for tokens, pos_seq, ner_seq in zip(all_word_tokens,\n",
        "                                    all_labels_pos_crf,\n",
        "                                    all_labels_ner_crf):\n",
        "    print(tokens)\n",
        "    print([pos_id2label[p] for p in pos_seq])\n",
        "    print([ner_id2label[n] for n in ner_seq])\n",
        "    print(\"---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-wiqAmwQnor"
      },
      "outputs": [],
      "source": [
        "all_labels_pos_crf = []\n",
        "all_labels_ner_crf = []\n",
        "\n",
        "all_words = []\n",
        "pad_ner_id = ner_label2id[\"PAD\"]\n",
        "\n",
        "for batch in val_loader_crf:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    input_id = batch['input_ids']\n",
        "    labels_pos = batch['labels_pos'].cpu().numpy()\n",
        "    labels_ner = batch['labels_ner'].cpu().numpy()\n",
        "\n",
        "\n",
        "    for lp in labels_pos:  # Iterate directly over the elements of labels_pos\n",
        "        mask = lp != -100\n",
        "        if mask.any():  # Check if there are any valid elements\n",
        "            all_labels_pos_crf.extend(lp[mask].tolist())\n",
        "\n",
        "    for ln_list in labels_ner:  # Iterate directly over the elements of labels_ner\n",
        "        for ln in ln_list:\n",
        "          if ln != pad_ner_id:\n",
        "              all_labels_ner_crf.append(ln)\n",
        "\n",
        "all_labels_pos_crf = [pos_id2label[label] for label in all_labels_pos_crf]\n",
        "all_labels_ner_crf = [ner_id2label[label] for label in all_labels_ner_crf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXZGfyyla5b-"
      },
      "outputs": [],
      "source": [
        "print(len(all_labels_pos_crf))\n",
        "print(len(all_labels_ner_crf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXAbHY4a8DTy"
      },
      "outputs": [],
      "source": [
        "#False Negatives\n",
        "\n",
        "store_idx = []\n",
        "label_find = 'I-PERSON'\n",
        "\n",
        "\n",
        "for idx, label in enumerate(all_labels_ner_crf):\n",
        "    if label == label_find:\n",
        "        store_idx.append(idx)\n",
        "\n",
        "print(store_idx)\n",
        "\n",
        "for idx in store_idx:\n",
        "    if preds_ner_crf[idx] != label_find:\n",
        "        print(preds_ner_crf[idx], idx,sep=' ', end='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNiibJ7W8Jpp"
      },
      "outputs": [],
      "source": [
        "#False Positives\n",
        "\n",
        "store_idx = []\n",
        "label_find = 'B-EVENT'\n",
        "\n",
        "\n",
        "for idx, label in enumerate(preds_ner_crf):\n",
        "    if label == label_find:\n",
        "        store_idx.append(idx)\n",
        "\n",
        "print(store_idx)\n",
        "\n",
        "for idx in store_idx:\n",
        "    if all_labels_ner_crf[idx] != label_find:\n",
        "        print(all_labels_ner_crf[idx], idx, end='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st8anzhGYcLN"
      },
      "source": [
        "## 5.3 Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeuADImYxdnO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class UnlabeledInferenceDataset(Dataset):\n",
        "    def __init__(self, encodings, tokens_list):\n",
        "        \"\"\"\n",
        "        encodings: dict with 'input_ids' and 'attention_mask' from your tokenizer\n",
        "        tokens_list: list of lists of original tokens per sentence\n",
        "        \"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.tokens_list = tokens_list.reset_index(drop=True) # Reset the index of tokens_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # No labels here—only inputs\n",
        "        item = {\n",
        "            'input_ids':     torch.as_tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask':torch.as_tensor(self.encodings['attention_mask'][idx]),\n",
        "            'tokens':        self.tokens_list.iloc[idx] # Access row data using iloc\n",
        "        }\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkbX2u_Q6wKA"
      },
      "outputs": [],
      "source": [
        "def predict_unlabeled(model, loader, device, pos_id2label, ner_id2label):\n",
        "    model.eval()\n",
        "    all_pos_preds = []  # will be List[List[str]]\n",
        "    all_ner_preds = []  # will be List[List[str]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            # POS predictions: (B, T)\n",
        "            preds_pos = outputs['logits_pos'].argmax(dim=-1).cpu().numpy()\n",
        "\n",
        "            # NER predictions via CRF decode: List[List[int]]\n",
        "            emissions = outputs['emissions_ner']\n",
        "            mask = attention_mask.bool()\n",
        "            preds_ner = model.crf.decode(emissions, mask=mask)\n",
        "\n",
        "            # For each sentence in the batch\n",
        "            for i, tokens in enumerate(batch['tokens']):\n",
        "                pos_seq = preds_pos[i]\n",
        "                ner_seq = preds_ner[i]\n",
        "                sent_pos = []\n",
        "                sent_ner = []\n",
        "\n",
        "                # For each token position j\n",
        "                for j, token in enumerate(tokens):\n",
        "                    # stop when mask says padding\n",
        "                    if j >= mask.shape[1] or not mask[i, j]:\n",
        "                        break\n",
        "                    sent_pos.append(pos_id2label[pos_seq[j]])\n",
        "                    sent_ner.append(ner_id2label[ner_seq[j]])\n",
        "\n",
        "                all_pos_preds.append(sent_pos)\n",
        "                all_ner_preds.append(sent_ner)\n",
        "\n",
        "    return all_pos_preds, all_ner_preds\n",
        "\n",
        "# --------------------------\n",
        "# USAGE EXAMPLE\n",
        "# --------------------------\n",
        "\n",
        "# Suppose you have:\n",
        "#   tokens_list = [['I','love','NY'], ['Hello','world','!'], …]\n",
        "#   encoded = tokenizer(tokens_list,\n",
        "#                       is_split_into_words=True,\n",
        "#                       padding=True, truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM2nsYgfh3bV"
      },
      "outputs": [],
      "source": [
        "dataset = UnlabeledInferenceDataset(encoded_val, val_set['tokens'])\n",
        "loader  = DataLoader(dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "pos_label_lists, ner_label_lists = predict_unlabeled(\n",
        "    model, loader, device, pos_id2label, ner_id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbPl0SlfQg39"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "envuQ0rsaYwV",
        "LdQUCFTIj7vz",
        "fZas9aZSYyEb",
        "kovedTwHU0bO",
        "vcF6JKHfV6xb",
        "qZ0QTc_MV1xL",
        "DCtd19CNYjzE",
        "st8anzhGYcLN"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}